{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 9918,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002016535591853196,
      "grad_norm": 6.3251142501831055,
      "learning_rate": 4.995462794918331e-05,
      "loss": 0.7747,
      "step": 10
    },
    {
      "epoch": 0.004033071183706392,
      "grad_norm": 3.38026762008667,
      "learning_rate": 4.9904214559386976e-05,
      "loss": 0.6956,
      "step": 20
    },
    {
      "epoch": 0.006049606775559589,
      "grad_norm": 1.4581713676452637,
      "learning_rate": 4.985380116959065e-05,
      "loss": 0.7121,
      "step": 30
    },
    {
      "epoch": 0.008066142367412784,
      "grad_norm": 3.8396778106689453,
      "learning_rate": 4.9803387779794316e-05,
      "loss": 0.6938,
      "step": 40
    },
    {
      "epoch": 0.01008267795926598,
      "grad_norm": 8.102599143981934,
      "learning_rate": 4.975297438999799e-05,
      "loss": 0.6843,
      "step": 50
    },
    {
      "epoch": 0.012099213551119177,
      "grad_norm": 3.1386618614196777,
      "learning_rate": 4.9702561000201656e-05,
      "loss": 0.6753,
      "step": 60
    },
    {
      "epoch": 0.014115749142972374,
      "grad_norm": 15.602036476135254,
      "learning_rate": 4.965214761040532e-05,
      "loss": 0.6601,
      "step": 70
    },
    {
      "epoch": 0.01613228473482557,
      "grad_norm": 17.884126663208008,
      "learning_rate": 4.9601734220608995e-05,
      "loss": 0.6653,
      "step": 80
    },
    {
      "epoch": 0.018148820326678767,
      "grad_norm": 1.0484999418258667,
      "learning_rate": 4.955132083081266e-05,
      "loss": 0.5637,
      "step": 90
    },
    {
      "epoch": 0.02016535591853196,
      "grad_norm": 10.297714233398438,
      "learning_rate": 4.9500907441016335e-05,
      "loss": 0.6394,
      "step": 100
    },
    {
      "epoch": 0.02218189151038516,
      "grad_norm": 5.078429698944092,
      "learning_rate": 4.945049405122001e-05,
      "loss": 0.6289,
      "step": 110
    },
    {
      "epoch": 0.024198427102238355,
      "grad_norm": 2.1044235229492188,
      "learning_rate": 4.9400080661423675e-05,
      "loss": 0.5751,
      "step": 120
    },
    {
      "epoch": 0.02621496269409155,
      "grad_norm": 10.01959228515625,
      "learning_rate": 4.934966727162735e-05,
      "loss": 0.4397,
      "step": 130
    },
    {
      "epoch": 0.028231498285944748,
      "grad_norm": 33.841651916503906,
      "learning_rate": 4.9299253881831015e-05,
      "loss": 0.4612,
      "step": 140
    },
    {
      "epoch": 0.030248033877797943,
      "grad_norm": 10.363471031188965,
      "learning_rate": 4.924884049203469e-05,
      "loss": 0.6569,
      "step": 150
    },
    {
      "epoch": 0.03226456946965114,
      "grad_norm": 23.276077270507812,
      "learning_rate": 4.919842710223836e-05,
      "loss": 0.5483,
      "step": 160
    },
    {
      "epoch": 0.034281105061504336,
      "grad_norm": 6.10534143447876,
      "learning_rate": 4.914801371244203e-05,
      "loss": 0.5988,
      "step": 170
    },
    {
      "epoch": 0.036297640653357534,
      "grad_norm": 9.08410930633545,
      "learning_rate": 4.90976003226457e-05,
      "loss": 0.5823,
      "step": 180
    },
    {
      "epoch": 0.038314176245210725,
      "grad_norm": 12.93310260772705,
      "learning_rate": 4.904718693284937e-05,
      "loss": 0.3702,
      "step": 190
    },
    {
      "epoch": 0.04033071183706392,
      "grad_norm": 28.953378677368164,
      "learning_rate": 4.899677354305304e-05,
      "loss": 0.5899,
      "step": 200
    },
    {
      "epoch": 0.04234724742891712,
      "grad_norm": 79.97979736328125,
      "learning_rate": 4.894636015325671e-05,
      "loss": 0.5596,
      "step": 210
    },
    {
      "epoch": 0.04436378302077032,
      "grad_norm": 48.95529556274414,
      "learning_rate": 4.8895946763460373e-05,
      "loss": 0.5341,
      "step": 220
    },
    {
      "epoch": 0.04638031861262351,
      "grad_norm": 5.7812371253967285,
      "learning_rate": 4.884553337366405e-05,
      "loss": 0.5252,
      "step": 230
    },
    {
      "epoch": 0.04839685420447671,
      "grad_norm": 17.778993606567383,
      "learning_rate": 4.879511998386771e-05,
      "loss": 0.5104,
      "step": 240
    },
    {
      "epoch": 0.05041338979632991,
      "grad_norm": 8.886297225952148,
      "learning_rate": 4.8744706594071386e-05,
      "loss": 0.4412,
      "step": 250
    },
    {
      "epoch": 0.0524299253881831,
      "grad_norm": 3.087899684906006,
      "learning_rate": 4.869429320427506e-05,
      "loss": 0.5104,
      "step": 260
    },
    {
      "epoch": 0.0544464609800363,
      "grad_norm": 8.154070854187012,
      "learning_rate": 4.8643879814478726e-05,
      "loss": 0.6518,
      "step": 270
    },
    {
      "epoch": 0.056462996571889496,
      "grad_norm": 12.808391571044922,
      "learning_rate": 4.85934664246824e-05,
      "loss": 0.4977,
      "step": 280
    },
    {
      "epoch": 0.05847953216374269,
      "grad_norm": 10.34648323059082,
      "learning_rate": 4.8543053034886066e-05,
      "loss": 0.5474,
      "step": 290
    },
    {
      "epoch": 0.060496067755595885,
      "grad_norm": 5.354915142059326,
      "learning_rate": 4.849263964508974e-05,
      "loss": 0.4253,
      "step": 300
    },
    {
      "epoch": 0.06251260334744908,
      "grad_norm": 43.117034912109375,
      "learning_rate": 4.844222625529341e-05,
      "loss": 0.3815,
      "step": 310
    },
    {
      "epoch": 0.06452913893930227,
      "grad_norm": 6.663754940032959,
      "learning_rate": 4.839181286549708e-05,
      "loss": 0.5766,
      "step": 320
    },
    {
      "epoch": 0.06654567453115548,
      "grad_norm": 15.890570640563965,
      "learning_rate": 4.834139947570075e-05,
      "loss": 0.5123,
      "step": 330
    },
    {
      "epoch": 0.06856221012300867,
      "grad_norm": 2.68202543258667,
      "learning_rate": 4.829098608590442e-05,
      "loss": 0.5493,
      "step": 340
    },
    {
      "epoch": 0.07057874571486186,
      "grad_norm": 2.311595916748047,
      "learning_rate": 4.8240572696108085e-05,
      "loss": 0.5995,
      "step": 350
    },
    {
      "epoch": 0.07259528130671507,
      "grad_norm": 3.3711624145507812,
      "learning_rate": 4.819015930631176e-05,
      "loss": 0.2969,
      "step": 360
    },
    {
      "epoch": 0.07461181689856826,
      "grad_norm": 4.193924903869629,
      "learning_rate": 4.8139745916515425e-05,
      "loss": 0.2656,
      "step": 370
    },
    {
      "epoch": 0.07662835249042145,
      "grad_norm": 6.626197814941406,
      "learning_rate": 4.80893325267191e-05,
      "loss": 0.5971,
      "step": 380
    },
    {
      "epoch": 0.07864488808227466,
      "grad_norm": 14.891219139099121,
      "learning_rate": 4.8038919136922765e-05,
      "loss": 0.5721,
      "step": 390
    },
    {
      "epoch": 0.08066142367412785,
      "grad_norm": 32.183258056640625,
      "learning_rate": 4.798850574712644e-05,
      "loss": 0.5321,
      "step": 400
    },
    {
      "epoch": 0.08267795926598104,
      "grad_norm": 4.22998571395874,
      "learning_rate": 4.793809235733011e-05,
      "loss": 0.434,
      "step": 410
    },
    {
      "epoch": 0.08469449485783424,
      "grad_norm": 117.84524536132812,
      "learning_rate": 4.788767896753378e-05,
      "loss": 0.4749,
      "step": 420
    },
    {
      "epoch": 0.08671103044968743,
      "grad_norm": 1.040871262550354,
      "learning_rate": 4.783726557773745e-05,
      "loss": 0.5394,
      "step": 430
    },
    {
      "epoch": 0.08872756604154064,
      "grad_norm": 171.6564483642578,
      "learning_rate": 4.778685218794112e-05,
      "loss": 0.5781,
      "step": 440
    },
    {
      "epoch": 0.09074410163339383,
      "grad_norm": 10.827489852905273,
      "learning_rate": 4.773643879814479e-05,
      "loss": 0.4234,
      "step": 450
    },
    {
      "epoch": 0.09276063722524702,
      "grad_norm": 43.62957000732422,
      "learning_rate": 4.7686025408348464e-05,
      "loss": 0.2572,
      "step": 460
    },
    {
      "epoch": 0.09477717281710023,
      "grad_norm": 99.05931091308594,
      "learning_rate": 4.763561201855213e-05,
      "loss": 0.6714,
      "step": 470
    },
    {
      "epoch": 0.09679370840895342,
      "grad_norm": 2.824101448059082,
      "learning_rate": 4.7585198628755803e-05,
      "loss": 0.5182,
      "step": 480
    },
    {
      "epoch": 0.09881024400080661,
      "grad_norm": 57.57345962524414,
      "learning_rate": 4.753478523895947e-05,
      "loss": 0.5713,
      "step": 490
    },
    {
      "epoch": 0.10082677959265982,
      "grad_norm": 15.936712265014648,
      "learning_rate": 4.7484371849163136e-05,
      "loss": 0.601,
      "step": 500
    },
    {
      "epoch": 0.102843315184513,
      "grad_norm": 20.87114715576172,
      "learning_rate": 4.743395845936681e-05,
      "loss": 0.5809,
      "step": 510
    },
    {
      "epoch": 0.1048598507763662,
      "grad_norm": 6.860533237457275,
      "learning_rate": 4.7383545069570476e-05,
      "loss": 0.4653,
      "step": 520
    },
    {
      "epoch": 0.1068763863682194,
      "grad_norm": 69.15593719482422,
      "learning_rate": 4.733313167977415e-05,
      "loss": 0.4631,
      "step": 530
    },
    {
      "epoch": 0.1088929219600726,
      "grad_norm": 3.426983594894409,
      "learning_rate": 4.7282718289977816e-05,
      "loss": 0.4896,
      "step": 540
    },
    {
      "epoch": 0.11090945755192579,
      "grad_norm": 1.3029762506484985,
      "learning_rate": 4.723230490018149e-05,
      "loss": 0.456,
      "step": 550
    },
    {
      "epoch": 0.11292599314377899,
      "grad_norm": 15.139031410217285,
      "learning_rate": 4.718189151038516e-05,
      "loss": 0.7377,
      "step": 560
    },
    {
      "epoch": 0.11494252873563218,
      "grad_norm": 24.52828598022461,
      "learning_rate": 4.713147812058883e-05,
      "loss": 0.4734,
      "step": 570
    },
    {
      "epoch": 0.11695906432748537,
      "grad_norm": 6.406589031219482,
      "learning_rate": 4.70810647307925e-05,
      "loss": 0.4161,
      "step": 580
    },
    {
      "epoch": 0.11897559991933858,
      "grad_norm": 4.695790767669678,
      "learning_rate": 4.7030651340996175e-05,
      "loss": 0.3652,
      "step": 590
    },
    {
      "epoch": 0.12099213551119177,
      "grad_norm": 2.857243537902832,
      "learning_rate": 4.698023795119984e-05,
      "loss": 0.4005,
      "step": 600
    },
    {
      "epoch": 0.12300867110304498,
      "grad_norm": 7.019220352172852,
      "learning_rate": 4.6929824561403515e-05,
      "loss": 0.4847,
      "step": 610
    },
    {
      "epoch": 0.12502520669489817,
      "grad_norm": 17.522293090820312,
      "learning_rate": 4.687941117160718e-05,
      "loss": 0.5001,
      "step": 620
    },
    {
      "epoch": 0.12704174228675136,
      "grad_norm": 4.138716697692871,
      "learning_rate": 4.6828997781810855e-05,
      "loss": 0.5529,
      "step": 630
    },
    {
      "epoch": 0.12905827787860455,
      "grad_norm": 4.911452293395996,
      "learning_rate": 4.677858439201452e-05,
      "loss": 0.3794,
      "step": 640
    },
    {
      "epoch": 0.13107481347045774,
      "grad_norm": 3.421004295349121,
      "learning_rate": 4.672817100221819e-05,
      "loss": 0.3637,
      "step": 650
    },
    {
      "epoch": 0.13309134906231096,
      "grad_norm": 323.85137939453125,
      "learning_rate": 4.667775761242186e-05,
      "loss": 0.6105,
      "step": 660
    },
    {
      "epoch": 0.13510788465416415,
      "grad_norm": 48.980987548828125,
      "learning_rate": 4.662734422262553e-05,
      "loss": 0.6204,
      "step": 670
    },
    {
      "epoch": 0.13712442024601734,
      "grad_norm": 57.113525390625,
      "learning_rate": 4.65769308328292e-05,
      "loss": 0.4363,
      "step": 680
    },
    {
      "epoch": 0.13914095583787053,
      "grad_norm": 9.41618537902832,
      "learning_rate": 4.6526517443032874e-05,
      "loss": 0.3373,
      "step": 690
    },
    {
      "epoch": 0.14115749142972372,
      "grad_norm": 2.5938291549682617,
      "learning_rate": 4.647610405323654e-05,
      "loss": 0.6711,
      "step": 700
    },
    {
      "epoch": 0.14317402702157694,
      "grad_norm": 17.112342834472656,
      "learning_rate": 4.6425690663440214e-05,
      "loss": 0.4784,
      "step": 710
    },
    {
      "epoch": 0.14519056261343014,
      "grad_norm": 10.95716381072998,
      "learning_rate": 4.637527727364388e-05,
      "loss": 0.3764,
      "step": 720
    },
    {
      "epoch": 0.14720709820528333,
      "grad_norm": 83.88426208496094,
      "learning_rate": 4.6324863883847554e-05,
      "loss": 0.4503,
      "step": 730
    },
    {
      "epoch": 0.14922363379713652,
      "grad_norm": 294.15234375,
      "learning_rate": 4.627445049405123e-05,
      "loss": 0.4576,
      "step": 740
    },
    {
      "epoch": 0.1512401693889897,
      "grad_norm": 24.229412078857422,
      "learning_rate": 4.622403710425489e-05,
      "loss": 0.6936,
      "step": 750
    },
    {
      "epoch": 0.1532567049808429,
      "grad_norm": 15.366830825805664,
      "learning_rate": 4.6173623714458566e-05,
      "loss": 0.4775,
      "step": 760
    },
    {
      "epoch": 0.15527324057269612,
      "grad_norm": 3.398618221282959,
      "learning_rate": 4.612321032466223e-05,
      "loss": 0.5289,
      "step": 770
    },
    {
      "epoch": 0.1572897761645493,
      "grad_norm": 2.3458545207977295,
      "learning_rate": 4.60727969348659e-05,
      "loss": 0.4418,
      "step": 780
    },
    {
      "epoch": 0.1593063117564025,
      "grad_norm": 15.624861717224121,
      "learning_rate": 4.602238354506957e-05,
      "loss": 0.431,
      "step": 790
    },
    {
      "epoch": 0.1613228473482557,
      "grad_norm": 0.8983088731765747,
      "learning_rate": 4.597197015527324e-05,
      "loss": 0.2612,
      "step": 800
    },
    {
      "epoch": 0.16333938294010888,
      "grad_norm": 53.10651779174805,
      "learning_rate": 4.592155676547691e-05,
      "loss": 0.6655,
      "step": 810
    },
    {
      "epoch": 0.16535591853196208,
      "grad_norm": 34.691627502441406,
      "learning_rate": 4.587114337568058e-05,
      "loss": 0.4753,
      "step": 820
    },
    {
      "epoch": 0.1673724541238153,
      "grad_norm": 16.797672271728516,
      "learning_rate": 4.582072998588425e-05,
      "loss": 0.3813,
      "step": 830
    },
    {
      "epoch": 0.1693889897156685,
      "grad_norm": 13.777878761291504,
      "learning_rate": 4.5770316596087925e-05,
      "loss": 0.5755,
      "step": 840
    },
    {
      "epoch": 0.17140552530752168,
      "grad_norm": 18.2769775390625,
      "learning_rate": 4.571990320629159e-05,
      "loss": 0.6581,
      "step": 850
    },
    {
      "epoch": 0.17342206089937487,
      "grad_norm": 2.4180166721343994,
      "learning_rate": 4.5669489816495265e-05,
      "loss": 0.5365,
      "step": 860
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 4.750256061553955,
      "learning_rate": 4.561907642669893e-05,
      "loss": 0.4616,
      "step": 870
    },
    {
      "epoch": 0.17745513208308128,
      "grad_norm": 3.0530710220336914,
      "learning_rate": 4.5568663036902605e-05,
      "loss": 0.5395,
      "step": 880
    },
    {
      "epoch": 0.17947166767493447,
      "grad_norm": 37.737545013427734,
      "learning_rate": 4.551824964710628e-05,
      "loss": 0.4873,
      "step": 890
    },
    {
      "epoch": 0.18148820326678766,
      "grad_norm": 5.227670192718506,
      "learning_rate": 4.5467836257309945e-05,
      "loss": 0.6546,
      "step": 900
    },
    {
      "epoch": 0.18350473885864085,
      "grad_norm": 6.041938304901123,
      "learning_rate": 4.541742286751362e-05,
      "loss": 0.4342,
      "step": 910
    },
    {
      "epoch": 0.18552127445049404,
      "grad_norm": 1.0510876178741455,
      "learning_rate": 4.5367009477717284e-05,
      "loss": 0.4145,
      "step": 920
    },
    {
      "epoch": 0.18753781004234724,
      "grad_norm": 8.763252258300781,
      "learning_rate": 4.531659608792095e-05,
      "loss": 0.7715,
      "step": 930
    },
    {
      "epoch": 0.18955434563420046,
      "grad_norm": 24.877347946166992,
      "learning_rate": 4.5266182698124624e-05,
      "loss": 0.4506,
      "step": 940
    },
    {
      "epoch": 0.19157088122605365,
      "grad_norm": 1.154148817062378,
      "learning_rate": 4.521576930832829e-05,
      "loss": 0.4667,
      "step": 950
    },
    {
      "epoch": 0.19358741681790684,
      "grad_norm": 37.64301300048828,
      "learning_rate": 4.5165355918531964e-05,
      "loss": 0.75,
      "step": 960
    },
    {
      "epoch": 0.19560395240976003,
      "grad_norm": 1.830055594444275,
      "learning_rate": 4.511494252873563e-05,
      "loss": 0.4922,
      "step": 970
    },
    {
      "epoch": 0.19762048800161322,
      "grad_norm": 6.639076232910156,
      "learning_rate": 4.5064529138939304e-05,
      "loss": 0.4809,
      "step": 980
    },
    {
      "epoch": 0.1996370235934664,
      "grad_norm": 3.1117143630981445,
      "learning_rate": 4.501411574914298e-05,
      "loss": 0.4763,
      "step": 990
    },
    {
      "epoch": 0.20165355918531963,
      "grad_norm": 2.7993714809417725,
      "learning_rate": 4.496370235934664e-05,
      "loss": 0.4851,
      "step": 1000
    },
    {
      "epoch": 0.20367009477717282,
      "grad_norm": 1.4614191055297852,
      "learning_rate": 4.4913288969550316e-05,
      "loss": 0.501,
      "step": 1010
    },
    {
      "epoch": 0.205686630369026,
      "grad_norm": 2.029136896133423,
      "learning_rate": 4.486287557975398e-05,
      "loss": 0.4636,
      "step": 1020
    },
    {
      "epoch": 0.2077031659608792,
      "grad_norm": 6.819509506225586,
      "learning_rate": 4.4812462189957656e-05,
      "loss": 0.5679,
      "step": 1030
    },
    {
      "epoch": 0.2097197015527324,
      "grad_norm": 31.158092498779297,
      "learning_rate": 4.476204880016133e-05,
      "loss": 0.3532,
      "step": 1040
    },
    {
      "epoch": 0.21173623714458562,
      "grad_norm": 2.9173922538757324,
      "learning_rate": 4.4711635410364996e-05,
      "loss": 0.6276,
      "step": 1050
    },
    {
      "epoch": 0.2137527727364388,
      "grad_norm": 64.59014129638672,
      "learning_rate": 4.466122202056867e-05,
      "loss": 0.4666,
      "step": 1060
    },
    {
      "epoch": 0.215769308328292,
      "grad_norm": 913.6600341796875,
      "learning_rate": 4.4610808630772336e-05,
      "loss": 0.4756,
      "step": 1070
    },
    {
      "epoch": 0.2177858439201452,
      "grad_norm": 119.31582641601562,
      "learning_rate": 4.4560395240976e-05,
      "loss": 0.4287,
      "step": 1080
    },
    {
      "epoch": 0.21980237951199838,
      "grad_norm": 8.449649810791016,
      "learning_rate": 4.4509981851179675e-05,
      "loss": 0.558,
      "step": 1090
    },
    {
      "epoch": 0.22181891510385157,
      "grad_norm": 3.218233108520508,
      "learning_rate": 4.445956846138334e-05,
      "loss": 0.4005,
      "step": 1100
    },
    {
      "epoch": 0.2238354506957048,
      "grad_norm": 6.687155246734619,
      "learning_rate": 4.4409155071587015e-05,
      "loss": 0.382,
      "step": 1110
    },
    {
      "epoch": 0.22585198628755798,
      "grad_norm": 4.727349281311035,
      "learning_rate": 4.435874168179068e-05,
      "loss": 0.6336,
      "step": 1120
    },
    {
      "epoch": 0.22786852187941117,
      "grad_norm": 25.4143009185791,
      "learning_rate": 4.4308328291994355e-05,
      "loss": 0.554,
      "step": 1130
    },
    {
      "epoch": 0.22988505747126436,
      "grad_norm": 2.1581077575683594,
      "learning_rate": 4.425791490219803e-05,
      "loss": 0.5413,
      "step": 1140
    },
    {
      "epoch": 0.23190159306311756,
      "grad_norm": 4.2266340255737305,
      "learning_rate": 4.4207501512401695e-05,
      "loss": 0.5973,
      "step": 1150
    },
    {
      "epoch": 0.23391812865497075,
      "grad_norm": 23.377227783203125,
      "learning_rate": 4.415708812260537e-05,
      "loss": 0.4858,
      "step": 1160
    },
    {
      "epoch": 0.23593466424682397,
      "grad_norm": 27.9072322845459,
      "learning_rate": 4.4106674732809034e-05,
      "loss": 0.4198,
      "step": 1170
    },
    {
      "epoch": 0.23795119983867716,
      "grad_norm": 2.8596487045288086,
      "learning_rate": 4.405626134301271e-05,
      "loss": 0.3895,
      "step": 1180
    },
    {
      "epoch": 0.23996773543053035,
      "grad_norm": 5.28351354598999,
      "learning_rate": 4.400584795321638e-05,
      "loss": 0.4667,
      "step": 1190
    },
    {
      "epoch": 0.24198427102238354,
      "grad_norm": 5.373502731323242,
      "learning_rate": 4.395543456342005e-05,
      "loss": 0.4034,
      "step": 1200
    },
    {
      "epoch": 0.24400080661423673,
      "grad_norm": 13.935046195983887,
      "learning_rate": 4.3905021173623714e-05,
      "loss": 0.4966,
      "step": 1210
    },
    {
      "epoch": 0.24601734220608995,
      "grad_norm": 10.802862167358398,
      "learning_rate": 4.385460778382739e-05,
      "loss": 0.3989,
      "step": 1220
    },
    {
      "epoch": 0.24803387779794314,
      "grad_norm": 34.460479736328125,
      "learning_rate": 4.3804194394031054e-05,
      "loss": 0.6746,
      "step": 1230
    },
    {
      "epoch": 0.25005041338979633,
      "grad_norm": 2.293374538421631,
      "learning_rate": 4.375378100423473e-05,
      "loss": 0.4423,
      "step": 1240
    },
    {
      "epoch": 0.25206694898164955,
      "grad_norm": 9.914669036865234,
      "learning_rate": 4.370336761443839e-05,
      "loss": 0.4238,
      "step": 1250
    },
    {
      "epoch": 0.2540834845735027,
      "grad_norm": 11.024669647216797,
      "learning_rate": 4.3652954224642067e-05,
      "loss": 0.5289,
      "step": 1260
    },
    {
      "epoch": 0.25610002016535593,
      "grad_norm": 24.991670608520508,
      "learning_rate": 4.360254083484574e-05,
      "loss": 0.5962,
      "step": 1270
    },
    {
      "epoch": 0.2581165557572091,
      "grad_norm": 28.668628692626953,
      "learning_rate": 4.3552127445049406e-05,
      "loss": 0.6532,
      "step": 1280
    },
    {
      "epoch": 0.2601330913490623,
      "grad_norm": 3.9254353046417236,
      "learning_rate": 4.350171405525308e-05,
      "loss": 0.4561,
      "step": 1290
    },
    {
      "epoch": 0.2621496269409155,
      "grad_norm": 5.584336757659912,
      "learning_rate": 4.3451300665456746e-05,
      "loss": 0.3203,
      "step": 1300
    },
    {
      "epoch": 0.2641661625327687,
      "grad_norm": 12.543373107910156,
      "learning_rate": 4.340088727566042e-05,
      "loss": 0.4486,
      "step": 1310
    },
    {
      "epoch": 0.2661826981246219,
      "grad_norm": 88.44658660888672,
      "learning_rate": 4.335047388586409e-05,
      "loss": 0.4909,
      "step": 1320
    },
    {
      "epoch": 0.2681992337164751,
      "grad_norm": 2.998595952987671,
      "learning_rate": 4.330006049606776e-05,
      "loss": 0.6075,
      "step": 1330
    },
    {
      "epoch": 0.2702157693083283,
      "grad_norm": 64.92391204833984,
      "learning_rate": 4.324964710627143e-05,
      "loss": 0.3269,
      "step": 1340
    },
    {
      "epoch": 0.27223230490018147,
      "grad_norm": 16.466598510742188,
      "learning_rate": 4.31992337164751e-05,
      "loss": 0.4075,
      "step": 1350
    },
    {
      "epoch": 0.2742488404920347,
      "grad_norm": 26.009033203125,
      "learning_rate": 4.3148820326678765e-05,
      "loss": 0.48,
      "step": 1360
    },
    {
      "epoch": 0.2762653760838879,
      "grad_norm": 15.461030006408691,
      "learning_rate": 4.309840693688244e-05,
      "loss": 0.473,
      "step": 1370
    },
    {
      "epoch": 0.27828191167574107,
      "grad_norm": 2.0539538860321045,
      "learning_rate": 4.3047993547086105e-05,
      "loss": 0.4754,
      "step": 1380
    },
    {
      "epoch": 0.2802984472675943,
      "grad_norm": 2.4636526107788086,
      "learning_rate": 4.299758015728978e-05,
      "loss": 0.3933,
      "step": 1390
    },
    {
      "epoch": 0.28231498285944745,
      "grad_norm": 1.3880057334899902,
      "learning_rate": 4.2947166767493445e-05,
      "loss": 0.3988,
      "step": 1400
    },
    {
      "epoch": 0.28433151845130067,
      "grad_norm": 14.329094886779785,
      "learning_rate": 4.289675337769712e-05,
      "loss": 0.4005,
      "step": 1410
    },
    {
      "epoch": 0.2863480540431539,
      "grad_norm": 8.46279239654541,
      "learning_rate": 4.284633998790079e-05,
      "loss": 0.6451,
      "step": 1420
    },
    {
      "epoch": 0.28836458963500705,
      "grad_norm": 3.428652286529541,
      "learning_rate": 4.279592659810446e-05,
      "loss": 0.3545,
      "step": 1430
    },
    {
      "epoch": 0.29038112522686027,
      "grad_norm": 1.0026053190231323,
      "learning_rate": 4.274551320830813e-05,
      "loss": 0.442,
      "step": 1440
    },
    {
      "epoch": 0.29239766081871343,
      "grad_norm": 8.371488571166992,
      "learning_rate": 4.26950998185118e-05,
      "loss": 0.4344,
      "step": 1450
    },
    {
      "epoch": 0.29441419641056665,
      "grad_norm": 1.5638272762298584,
      "learning_rate": 4.264468642871547e-05,
      "loss": 0.3671,
      "step": 1460
    },
    {
      "epoch": 0.2964307320024198,
      "grad_norm": 2.3419878482818604,
      "learning_rate": 4.2594273038919144e-05,
      "loss": 0.4794,
      "step": 1470
    },
    {
      "epoch": 0.29844726759427304,
      "grad_norm": 35.777183532714844,
      "learning_rate": 4.254385964912281e-05,
      "loss": 0.455,
      "step": 1480
    },
    {
      "epoch": 0.30046380318612625,
      "grad_norm": 15.461639404296875,
      "learning_rate": 4.2493446259326484e-05,
      "loss": 0.5237,
      "step": 1490
    },
    {
      "epoch": 0.3024803387779794,
      "grad_norm": 1.1361567974090576,
      "learning_rate": 4.244303286953015e-05,
      "loss": 0.4982,
      "step": 1500
    },
    {
      "epoch": 0.30449687436983264,
      "grad_norm": 4.3481903076171875,
      "learning_rate": 4.2392619479733817e-05,
      "loss": 0.3982,
      "step": 1510
    },
    {
      "epoch": 0.3065134099616858,
      "grad_norm": 8.21597671508789,
      "learning_rate": 4.234220608993749e-05,
      "loss": 0.504,
      "step": 1520
    },
    {
      "epoch": 0.308529945553539,
      "grad_norm": 5.3722243309021,
      "learning_rate": 4.2291792700141156e-05,
      "loss": 0.4432,
      "step": 1530
    },
    {
      "epoch": 0.31054648114539224,
      "grad_norm": 19.8753662109375,
      "learning_rate": 4.224137931034483e-05,
      "loss": 0.3395,
      "step": 1540
    },
    {
      "epoch": 0.3125630167372454,
      "grad_norm": 4.054671764373779,
      "learning_rate": 4.2190965920548496e-05,
      "loss": 0.2947,
      "step": 1550
    },
    {
      "epoch": 0.3145795523290986,
      "grad_norm": 2.2235262393951416,
      "learning_rate": 4.214055253075217e-05,
      "loss": 0.362,
      "step": 1560
    },
    {
      "epoch": 0.3165960879209518,
      "grad_norm": 17.058658599853516,
      "learning_rate": 4.209013914095584e-05,
      "loss": 0.2832,
      "step": 1570
    },
    {
      "epoch": 0.318612623512805,
      "grad_norm": 16.9038143157959,
      "learning_rate": 4.203972575115951e-05,
      "loss": 0.4332,
      "step": 1580
    },
    {
      "epoch": 0.3206291591046582,
      "grad_norm": 20.07639503479004,
      "learning_rate": 4.198931236136318e-05,
      "loss": 0.6299,
      "step": 1590
    },
    {
      "epoch": 0.3226456946965114,
      "grad_norm": 1.18110990524292,
      "learning_rate": 4.193889897156685e-05,
      "loss": 0.3437,
      "step": 1600
    },
    {
      "epoch": 0.3246622302883646,
      "grad_norm": 5.231297016143799,
      "learning_rate": 4.188848558177052e-05,
      "loss": 0.3893,
      "step": 1610
    },
    {
      "epoch": 0.32667876588021777,
      "grad_norm": 21.541269302368164,
      "learning_rate": 4.1838072191974195e-05,
      "loss": 0.4539,
      "step": 1620
    },
    {
      "epoch": 0.328695301472071,
      "grad_norm": 7.009695053100586,
      "learning_rate": 4.178765880217786e-05,
      "loss": 0.685,
      "step": 1630
    },
    {
      "epoch": 0.33071183706392415,
      "grad_norm": 9.201099395751953,
      "learning_rate": 4.173724541238153e-05,
      "loss": 0.3396,
      "step": 1640
    },
    {
      "epoch": 0.33272837265577737,
      "grad_norm": 41.887271881103516,
      "learning_rate": 4.16868320225852e-05,
      "loss": 0.5418,
      "step": 1650
    },
    {
      "epoch": 0.3347449082476306,
      "grad_norm": 8.581245422363281,
      "learning_rate": 4.163641863278887e-05,
      "loss": 0.5046,
      "step": 1660
    },
    {
      "epoch": 0.33676144383948375,
      "grad_norm": 2.1884119510650635,
      "learning_rate": 4.158600524299254e-05,
      "loss": 0.3964,
      "step": 1670
    },
    {
      "epoch": 0.338777979431337,
      "grad_norm": 13.642645835876465,
      "learning_rate": 4.153559185319621e-05,
      "loss": 0.472,
      "step": 1680
    },
    {
      "epoch": 0.34079451502319014,
      "grad_norm": 0.9501444697380066,
      "learning_rate": 4.148517846339988e-05,
      "loss": 0.4514,
      "step": 1690
    },
    {
      "epoch": 0.34281105061504336,
      "grad_norm": 8.458125114440918,
      "learning_rate": 4.143476507360355e-05,
      "loss": 0.5004,
      "step": 1700
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 89.03797912597656,
      "learning_rate": 4.138435168380722e-05,
      "loss": 0.4781,
      "step": 1710
    },
    {
      "epoch": 0.34684412179874974,
      "grad_norm": 10.870992660522461,
      "learning_rate": 4.1333938294010894e-05,
      "loss": 0.4549,
      "step": 1720
    },
    {
      "epoch": 0.34886065739060296,
      "grad_norm": 18.687591552734375,
      "learning_rate": 4.128352490421456e-05,
      "loss": 0.3608,
      "step": 1730
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 10.046449661254883,
      "learning_rate": 4.1233111514418234e-05,
      "loss": 0.454,
      "step": 1740
    },
    {
      "epoch": 0.35289372857430934,
      "grad_norm": 1.7334016561508179,
      "learning_rate": 4.11826981246219e-05,
      "loss": 0.3418,
      "step": 1750
    },
    {
      "epoch": 0.35491026416616256,
      "grad_norm": 25.669559478759766,
      "learning_rate": 4.113228473482557e-05,
      "loss": 0.5377,
      "step": 1760
    },
    {
      "epoch": 0.3569267997580157,
      "grad_norm": 10.520331382751465,
      "learning_rate": 4.1081871345029247e-05,
      "loss": 0.5483,
      "step": 1770
    },
    {
      "epoch": 0.35894333534986894,
      "grad_norm": 9.744111061096191,
      "learning_rate": 4.103145795523291e-05,
      "loss": 0.4328,
      "step": 1780
    },
    {
      "epoch": 0.3609598709417221,
      "grad_norm": 14.984160423278809,
      "learning_rate": 4.098104456543658e-05,
      "loss": 0.2951,
      "step": 1790
    },
    {
      "epoch": 0.3629764065335753,
      "grad_norm": 4.485157489776611,
      "learning_rate": 4.093063117564025e-05,
      "loss": 0.5819,
      "step": 1800
    },
    {
      "epoch": 0.3649929421254285,
      "grad_norm": 7.199477195739746,
      "learning_rate": 4.088021778584392e-05,
      "loss": 0.6501,
      "step": 1810
    },
    {
      "epoch": 0.3670094777172817,
      "grad_norm": 5.267457485198975,
      "learning_rate": 4.082980439604759e-05,
      "loss": 0.5246,
      "step": 1820
    },
    {
      "epoch": 0.3690260133091349,
      "grad_norm": 1.4832630157470703,
      "learning_rate": 4.077939100625126e-05,
      "loss": 0.3339,
      "step": 1830
    },
    {
      "epoch": 0.3710425489009881,
      "grad_norm": 16.284685134887695,
      "learning_rate": 4.072897761645493e-05,
      "loss": 0.5029,
      "step": 1840
    },
    {
      "epoch": 0.3730590844928413,
      "grad_norm": 0.6094575524330139,
      "learning_rate": 4.06785642266586e-05,
      "loss": 0.2967,
      "step": 1850
    },
    {
      "epoch": 0.37507562008469447,
      "grad_norm": 2.7400195598602295,
      "learning_rate": 4.062815083686227e-05,
      "loss": 0.8018,
      "step": 1860
    },
    {
      "epoch": 0.3770921556765477,
      "grad_norm": 38.82992935180664,
      "learning_rate": 4.0577737447065945e-05,
      "loss": 0.4231,
      "step": 1870
    },
    {
      "epoch": 0.3791086912684009,
      "grad_norm": 1.9953519105911255,
      "learning_rate": 4.052732405726961e-05,
      "loss": 0.3829,
      "step": 1880
    },
    {
      "epoch": 0.3811252268602541,
      "grad_norm": 4.844915866851807,
      "learning_rate": 4.0476910667473285e-05,
      "loss": 0.5126,
      "step": 1890
    },
    {
      "epoch": 0.3831417624521073,
      "grad_norm": 6.72674560546875,
      "learning_rate": 4.042649727767695e-05,
      "loss": 0.4193,
      "step": 1900
    },
    {
      "epoch": 0.38515829804396046,
      "grad_norm": 64.90362548828125,
      "learning_rate": 4.0376083887880625e-05,
      "loss": 0.4043,
      "step": 1910
    },
    {
      "epoch": 0.3871748336358137,
      "grad_norm": 5.074402809143066,
      "learning_rate": 4.03256704980843e-05,
      "loss": 0.2573,
      "step": 1920
    },
    {
      "epoch": 0.3891913692276669,
      "grad_norm": 28.936710357666016,
      "learning_rate": 4.0275257108287964e-05,
      "loss": 0.3753,
      "step": 1930
    },
    {
      "epoch": 0.39120790481952006,
      "grad_norm": 0.6120311617851257,
      "learning_rate": 4.022484371849163e-05,
      "loss": 0.2521,
      "step": 1940
    },
    {
      "epoch": 0.3932244404113733,
      "grad_norm": 49.1609001159668,
      "learning_rate": 4.0174430328695304e-05,
      "loss": 0.5211,
      "step": 1950
    },
    {
      "epoch": 0.39524097600322644,
      "grad_norm": 1.3137930631637573,
      "learning_rate": 4.012401693889897e-05,
      "loss": 0.3206,
      "step": 1960
    },
    {
      "epoch": 0.39725751159507966,
      "grad_norm": 6.462067127227783,
      "learning_rate": 4.0073603549102644e-05,
      "loss": 0.4101,
      "step": 1970
    },
    {
      "epoch": 0.3992740471869328,
      "grad_norm": 66.16756439208984,
      "learning_rate": 4.002319015930631e-05,
      "loss": 0.3411,
      "step": 1980
    },
    {
      "epoch": 0.40129058277878604,
      "grad_norm": 19.80302619934082,
      "learning_rate": 3.9972776769509984e-05,
      "loss": 0.4435,
      "step": 1990
    },
    {
      "epoch": 0.40330711837063926,
      "grad_norm": 2.7159650325775146,
      "learning_rate": 3.992236337971366e-05,
      "loss": 0.5018,
      "step": 2000
    },
    {
      "epoch": 0.4053236539624924,
      "grad_norm": 2.265105962753296,
      "learning_rate": 3.987194998991732e-05,
      "loss": 0.6625,
      "step": 2010
    },
    {
      "epoch": 0.40734018955434564,
      "grad_norm": 5.443859100341797,
      "learning_rate": 3.9821536600120997e-05,
      "loss": 0.4884,
      "step": 2020
    },
    {
      "epoch": 0.4093567251461988,
      "grad_norm": 6.893690586090088,
      "learning_rate": 3.977112321032466e-05,
      "loss": 0.3746,
      "step": 2030
    },
    {
      "epoch": 0.411373260738052,
      "grad_norm": 1.9668190479278564,
      "learning_rate": 3.9720709820528336e-05,
      "loss": 0.4108,
      "step": 2040
    },
    {
      "epoch": 0.41338979632990525,
      "grad_norm": 51.9446907043457,
      "learning_rate": 3.967029643073201e-05,
      "loss": 0.5906,
      "step": 2050
    },
    {
      "epoch": 0.4154063319217584,
      "grad_norm": 1.497475028038025,
      "learning_rate": 3.9619883040935676e-05,
      "loss": 0.3855,
      "step": 2060
    },
    {
      "epoch": 0.41742286751361163,
      "grad_norm": 11.024585723876953,
      "learning_rate": 3.956946965113935e-05,
      "loss": 0.3762,
      "step": 2070
    },
    {
      "epoch": 0.4194394031054648,
      "grad_norm": 49.5217170715332,
      "learning_rate": 3.9519056261343016e-05,
      "loss": 0.271,
      "step": 2080
    },
    {
      "epoch": 0.421455938697318,
      "grad_norm": 28.671188354492188,
      "learning_rate": 3.946864287154668e-05,
      "loss": 0.4579,
      "step": 2090
    },
    {
      "epoch": 0.42347247428917123,
      "grad_norm": 5.4868597984313965,
      "learning_rate": 3.9418229481750355e-05,
      "loss": 0.5151,
      "step": 2100
    },
    {
      "epoch": 0.4254890098810244,
      "grad_norm": 18.534650802612305,
      "learning_rate": 3.936781609195402e-05,
      "loss": 0.3342,
      "step": 2110
    },
    {
      "epoch": 0.4275055454728776,
      "grad_norm": 5.700922012329102,
      "learning_rate": 3.9317402702157695e-05,
      "loss": 0.3992,
      "step": 2120
    },
    {
      "epoch": 0.4295220810647308,
      "grad_norm": 3.594521999359131,
      "learning_rate": 3.926698931236136e-05,
      "loss": 0.4706,
      "step": 2130
    },
    {
      "epoch": 0.431538616656584,
      "grad_norm": 3.5803728103637695,
      "learning_rate": 3.9216575922565035e-05,
      "loss": 0.3665,
      "step": 2140
    },
    {
      "epoch": 0.43355515224843716,
      "grad_norm": 2.8562467098236084,
      "learning_rate": 3.916616253276871e-05,
      "loss": 0.4391,
      "step": 2150
    },
    {
      "epoch": 0.4355716878402904,
      "grad_norm": 1.2840138673782349,
      "learning_rate": 3.9115749142972375e-05,
      "loss": 0.4049,
      "step": 2160
    },
    {
      "epoch": 0.4375882234321436,
      "grad_norm": 3.2650842666625977,
      "learning_rate": 3.906533575317605e-05,
      "loss": 0.369,
      "step": 2170
    },
    {
      "epoch": 0.43960475902399676,
      "grad_norm": 53.37433624267578,
      "learning_rate": 3.9014922363379714e-05,
      "loss": 0.2682,
      "step": 2180
    },
    {
      "epoch": 0.44162129461585,
      "grad_norm": 15.493186950683594,
      "learning_rate": 3.896450897358339e-05,
      "loss": 0.2506,
      "step": 2190
    },
    {
      "epoch": 0.44363783020770314,
      "grad_norm": 2.4735114574432373,
      "learning_rate": 3.891409558378706e-05,
      "loss": 0.4199,
      "step": 2200
    },
    {
      "epoch": 0.44565436579955636,
      "grad_norm": 8.908304214477539,
      "learning_rate": 3.886368219399073e-05,
      "loss": 0.6762,
      "step": 2210
    },
    {
      "epoch": 0.4476709013914096,
      "grad_norm": 5.515600204467773,
      "learning_rate": 3.8813268804194394e-05,
      "loss": 0.4666,
      "step": 2220
    },
    {
      "epoch": 0.44968743698326274,
      "grad_norm": 3.4795212745666504,
      "learning_rate": 3.876285541439807e-05,
      "loss": 0.4109,
      "step": 2230
    },
    {
      "epoch": 0.45170397257511596,
      "grad_norm": 20.214555740356445,
      "learning_rate": 3.8712442024601734e-05,
      "loss": 0.4896,
      "step": 2240
    },
    {
      "epoch": 0.4537205081669691,
      "grad_norm": 7.0811967849731445,
      "learning_rate": 3.866202863480541e-05,
      "loss": 0.4929,
      "step": 2250
    },
    {
      "epoch": 0.45573704375882235,
      "grad_norm": 3.0693862438201904,
      "learning_rate": 3.861161524500907e-05,
      "loss": 0.4406,
      "step": 2260
    },
    {
      "epoch": 0.45775357935067557,
      "grad_norm": 9.070863723754883,
      "learning_rate": 3.8561201855212747e-05,
      "loss": 0.3965,
      "step": 2270
    },
    {
      "epoch": 0.45977011494252873,
      "grad_norm": 1.5101827383041382,
      "learning_rate": 3.851078846541641e-05,
      "loss": 0.3208,
      "step": 2280
    },
    {
      "epoch": 0.46178665053438195,
      "grad_norm": 2.320906162261963,
      "learning_rate": 3.8460375075620086e-05,
      "loss": 0.4386,
      "step": 2290
    },
    {
      "epoch": 0.4638031861262351,
      "grad_norm": 6.660170078277588,
      "learning_rate": 3.840996168582376e-05,
      "loss": 0.4048,
      "step": 2300
    },
    {
      "epoch": 0.46581972171808833,
      "grad_norm": 6.125809192657471,
      "learning_rate": 3.8359548296027426e-05,
      "loss": 0.2768,
      "step": 2310
    },
    {
      "epoch": 0.4678362573099415,
      "grad_norm": 3.5966784954071045,
      "learning_rate": 3.83091349062311e-05,
      "loss": 0.4789,
      "step": 2320
    },
    {
      "epoch": 0.4698527929017947,
      "grad_norm": 28.034576416015625,
      "learning_rate": 3.8258721516434766e-05,
      "loss": 0.5096,
      "step": 2330
    },
    {
      "epoch": 0.47186932849364793,
      "grad_norm": 3.1466729640960693,
      "learning_rate": 3.820830812663844e-05,
      "loss": 0.5341,
      "step": 2340
    },
    {
      "epoch": 0.4738858640855011,
      "grad_norm": 1.7981746196746826,
      "learning_rate": 3.815789473684211e-05,
      "loss": 0.3528,
      "step": 2350
    },
    {
      "epoch": 0.4759023996773543,
      "grad_norm": 2.2884998321533203,
      "learning_rate": 3.810748134704578e-05,
      "loss": 0.4444,
      "step": 2360
    },
    {
      "epoch": 0.4779189352692075,
      "grad_norm": 83.65898132324219,
      "learning_rate": 3.8057067957249445e-05,
      "loss": 0.4006,
      "step": 2370
    },
    {
      "epoch": 0.4799354708610607,
      "grad_norm": 2.235231876373291,
      "learning_rate": 3.800665456745311e-05,
      "loss": 0.4811,
      "step": 2380
    },
    {
      "epoch": 0.4819520064529139,
      "grad_norm": 26.553314208984375,
      "learning_rate": 3.7956241177656785e-05,
      "loss": 0.3389,
      "step": 2390
    },
    {
      "epoch": 0.4839685420447671,
      "grad_norm": 18.576398849487305,
      "learning_rate": 3.790582778786046e-05,
      "loss": 0.241,
      "step": 2400
    },
    {
      "epoch": 0.4859850776366203,
      "grad_norm": 5.197652339935303,
      "learning_rate": 3.7855414398064125e-05,
      "loss": 0.5346,
      "step": 2410
    },
    {
      "epoch": 0.48800161322847346,
      "grad_norm": 78.6335220336914,
      "learning_rate": 3.78050010082678e-05,
      "loss": 0.5029,
      "step": 2420
    },
    {
      "epoch": 0.4900181488203267,
      "grad_norm": 18.544422149658203,
      "learning_rate": 3.7754587618471464e-05,
      "loss": 0.4256,
      "step": 2430
    },
    {
      "epoch": 0.4920346844121799,
      "grad_norm": 1.1685055494308472,
      "learning_rate": 3.770417422867514e-05,
      "loss": 0.3558,
      "step": 2440
    },
    {
      "epoch": 0.49405122000403306,
      "grad_norm": 2.541379928588867,
      "learning_rate": 3.765376083887881e-05,
      "loss": 0.4863,
      "step": 2450
    },
    {
      "epoch": 0.4960677555958863,
      "grad_norm": 20.007572174072266,
      "learning_rate": 3.760334744908248e-05,
      "loss": 0.4206,
      "step": 2460
    },
    {
      "epoch": 0.49808429118773945,
      "grad_norm": 133.8644561767578,
      "learning_rate": 3.755293405928615e-05,
      "loss": 0.5243,
      "step": 2470
    },
    {
      "epoch": 0.5001008267795927,
      "grad_norm": 11.472935676574707,
      "learning_rate": 3.750252066948982e-05,
      "loss": 0.3189,
      "step": 2480
    },
    {
      "epoch": 0.5021173623714459,
      "grad_norm": 2.0812811851501465,
      "learning_rate": 3.745210727969349e-05,
      "loss": 0.2735,
      "step": 2490
    },
    {
      "epoch": 0.5041338979632991,
      "grad_norm": 31.7398738861084,
      "learning_rate": 3.7401693889897164e-05,
      "loss": 0.3867,
      "step": 2500
    },
    {
      "epoch": 0.5061504335551522,
      "grad_norm": 6.707540988922119,
      "learning_rate": 3.735128050010083e-05,
      "loss": 0.4212,
      "step": 2510
    },
    {
      "epoch": 0.5081669691470054,
      "grad_norm": 1.3248884677886963,
      "learning_rate": 3.7300867110304497e-05,
      "loss": 0.5028,
      "step": 2520
    },
    {
      "epoch": 0.5101835047388587,
      "grad_norm": 4.452311992645264,
      "learning_rate": 3.725045372050816e-05,
      "loss": 0.5189,
      "step": 2530
    },
    {
      "epoch": 0.5122000403307119,
      "grad_norm": 3.3496809005737305,
      "learning_rate": 3.7200040330711836e-05,
      "loss": 0.4199,
      "step": 2540
    },
    {
      "epoch": 0.514216575922565,
      "grad_norm": 1.530256748199463,
      "learning_rate": 3.714962694091551e-05,
      "loss": 0.3591,
      "step": 2550
    },
    {
      "epoch": 0.5162331115144182,
      "grad_norm": 2.1021437644958496,
      "learning_rate": 3.7099213551119176e-05,
      "loss": 0.3933,
      "step": 2560
    },
    {
      "epoch": 0.5182496471062714,
      "grad_norm": 0.7409253120422363,
      "learning_rate": 3.704880016132285e-05,
      "loss": 0.4326,
      "step": 2570
    },
    {
      "epoch": 0.5202661826981246,
      "grad_norm": 23.015026092529297,
      "learning_rate": 3.6998386771526516e-05,
      "loss": 0.3963,
      "step": 2580
    },
    {
      "epoch": 0.5222827182899779,
      "grad_norm": 10.620753288269043,
      "learning_rate": 3.694797338173019e-05,
      "loss": 0.5518,
      "step": 2590
    },
    {
      "epoch": 0.524299253881831,
      "grad_norm": 150.16041564941406,
      "learning_rate": 3.689755999193386e-05,
      "loss": 0.5655,
      "step": 2600
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 1.2485624551773071,
      "learning_rate": 3.684714660213753e-05,
      "loss": 0.2898,
      "step": 2610
    },
    {
      "epoch": 0.5283323250655374,
      "grad_norm": 4.767935276031494,
      "learning_rate": 3.67967332123412e-05,
      "loss": 0.5975,
      "step": 2620
    },
    {
      "epoch": 0.5303488606573906,
      "grad_norm": 84.25980377197266,
      "learning_rate": 3.6746319822544875e-05,
      "loss": 0.5561,
      "step": 2630
    },
    {
      "epoch": 0.5323653962492438,
      "grad_norm": 3.532393217086792,
      "learning_rate": 3.669590643274854e-05,
      "loss": 0.3589,
      "step": 2640
    },
    {
      "epoch": 0.534381931841097,
      "grad_norm": 15.6353120803833,
      "learning_rate": 3.664549304295221e-05,
      "loss": 0.2622,
      "step": 2650
    },
    {
      "epoch": 0.5363984674329502,
      "grad_norm": 35.31687545776367,
      "learning_rate": 3.659507965315588e-05,
      "loss": 0.3289,
      "step": 2660
    },
    {
      "epoch": 0.5384150030248034,
      "grad_norm": 1.7421746253967285,
      "learning_rate": 3.654466626335955e-05,
      "loss": 0.2635,
      "step": 2670
    },
    {
      "epoch": 0.5404315386166566,
      "grad_norm": 3.3342981338500977,
      "learning_rate": 3.649425287356322e-05,
      "loss": 0.5499,
      "step": 2680
    },
    {
      "epoch": 0.5424480742085098,
      "grad_norm": 1.8787602186203003,
      "learning_rate": 3.644383948376689e-05,
      "loss": 0.4929,
      "step": 2690
    },
    {
      "epoch": 0.5444646098003629,
      "grad_norm": 0.6427419185638428,
      "learning_rate": 3.639342609397056e-05,
      "loss": 0.4066,
      "step": 2700
    },
    {
      "epoch": 0.5464811453922161,
      "grad_norm": 1.8744187355041504,
      "learning_rate": 3.634301270417423e-05,
      "loss": 0.2913,
      "step": 2710
    },
    {
      "epoch": 0.5484976809840694,
      "grad_norm": 2.263786792755127,
      "learning_rate": 3.62925993143779e-05,
      "loss": 0.4764,
      "step": 2720
    },
    {
      "epoch": 0.5505142165759226,
      "grad_norm": 1.4821442365646362,
      "learning_rate": 3.6242185924581574e-05,
      "loss": 0.4588,
      "step": 2730
    },
    {
      "epoch": 0.5525307521677758,
      "grad_norm": 2.323385238647461,
      "learning_rate": 3.619177253478524e-05,
      "loss": 0.4406,
      "step": 2740
    },
    {
      "epoch": 0.5545472877596289,
      "grad_norm": 13.651862144470215,
      "learning_rate": 3.6141359144988914e-05,
      "loss": 0.3957,
      "step": 2750
    },
    {
      "epoch": 0.5565638233514821,
      "grad_norm": 7.042654991149902,
      "learning_rate": 3.609094575519258e-05,
      "loss": 0.3529,
      "step": 2760
    },
    {
      "epoch": 0.5585803589433354,
      "grad_norm": 0.8278635144233704,
      "learning_rate": 3.604053236539625e-05,
      "loss": 0.364,
      "step": 2770
    },
    {
      "epoch": 0.5605968945351886,
      "grad_norm": 6.926609992980957,
      "learning_rate": 3.599011897559993e-05,
      "loss": 0.424,
      "step": 2780
    },
    {
      "epoch": 0.5626134301270418,
      "grad_norm": 37.56672286987305,
      "learning_rate": 3.593970558580359e-05,
      "loss": 0.2766,
      "step": 2790
    },
    {
      "epoch": 0.5646299657188949,
      "grad_norm": 19.444351196289062,
      "learning_rate": 3.588929219600726e-05,
      "loss": 0.5918,
      "step": 2800
    },
    {
      "epoch": 0.5666465013107481,
      "grad_norm": 1.5324490070343018,
      "learning_rate": 3.5838878806210926e-05,
      "loss": 0.5514,
      "step": 2810
    },
    {
      "epoch": 0.5686630369026013,
      "grad_norm": 3.873739242553711,
      "learning_rate": 3.57884654164146e-05,
      "loss": 0.4118,
      "step": 2820
    },
    {
      "epoch": 0.5706795724944546,
      "grad_norm": 27.348297119140625,
      "learning_rate": 3.573805202661827e-05,
      "loss": 0.4084,
      "step": 2830
    },
    {
      "epoch": 0.5726961080863078,
      "grad_norm": 4.256318092346191,
      "learning_rate": 3.568763863682194e-05,
      "loss": 0.443,
      "step": 2840
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 11.014415740966797,
      "learning_rate": 3.563722524702561e-05,
      "loss": 0.3379,
      "step": 2850
    },
    {
      "epoch": 0.5767291792700141,
      "grad_norm": 58.10097122192383,
      "learning_rate": 3.558681185722928e-05,
      "loss": 0.3814,
      "step": 2860
    },
    {
      "epoch": 0.5787457148618673,
      "grad_norm": 2.428056478500366,
      "learning_rate": 3.553639846743295e-05,
      "loss": 0.3583,
      "step": 2870
    },
    {
      "epoch": 0.5807622504537205,
      "grad_norm": 11.999417304992676,
      "learning_rate": 3.5485985077636625e-05,
      "loss": 0.5034,
      "step": 2880
    },
    {
      "epoch": 0.5827787860455736,
      "grad_norm": 10.633814811706543,
      "learning_rate": 3.543557168784029e-05,
      "loss": 0.5274,
      "step": 2890
    },
    {
      "epoch": 0.5847953216374269,
      "grad_norm": 1.889489769935608,
      "learning_rate": 3.5385158298043965e-05,
      "loss": 0.283,
      "step": 2900
    },
    {
      "epoch": 0.5868118572292801,
      "grad_norm": 11.582491874694824,
      "learning_rate": 3.533474490824763e-05,
      "loss": 0.3576,
      "step": 2910
    },
    {
      "epoch": 0.5888283928211333,
      "grad_norm": 74.70707702636719,
      "learning_rate": 3.5284331518451305e-05,
      "loss": 0.3989,
      "step": 2920
    },
    {
      "epoch": 0.5908449284129865,
      "grad_norm": 0.6735146045684814,
      "learning_rate": 3.523391812865498e-05,
      "loss": 0.5637,
      "step": 2930
    },
    {
      "epoch": 0.5928614640048396,
      "grad_norm": 1.1953072547912598,
      "learning_rate": 3.5183504738858644e-05,
      "loss": 0.4998,
      "step": 2940
    },
    {
      "epoch": 0.5948779995966929,
      "grad_norm": 1.6057780981063843,
      "learning_rate": 3.513309134906231e-05,
      "loss": 0.3721,
      "step": 2950
    },
    {
      "epoch": 0.5968945351885461,
      "grad_norm": 3.1911275386810303,
      "learning_rate": 3.508267795926598e-05,
      "loss": 0.5008,
      "step": 2960
    },
    {
      "epoch": 0.5989110707803993,
      "grad_norm": 12.22616958618164,
      "learning_rate": 3.503226456946965e-05,
      "loss": 0.4707,
      "step": 2970
    },
    {
      "epoch": 0.6009276063722525,
      "grad_norm": 1.3646332025527954,
      "learning_rate": 3.4981851179673324e-05,
      "loss": 0.4391,
      "step": 2980
    },
    {
      "epoch": 0.6029441419641056,
      "grad_norm": 3.6762025356292725,
      "learning_rate": 3.493143778987699e-05,
      "loss": 0.3547,
      "step": 2990
    },
    {
      "epoch": 0.6049606775559588,
      "grad_norm": 1.1792908906936646,
      "learning_rate": 3.4881024400080664e-05,
      "loss": 0.3419,
      "step": 3000
    },
    {
      "epoch": 0.6069772131478121,
      "grad_norm": 7.872889995574951,
      "learning_rate": 3.483061101028433e-05,
      "loss": 0.3933,
      "step": 3010
    },
    {
      "epoch": 0.6089937487396653,
      "grad_norm": 1.1725422143936157,
      "learning_rate": 3.4780197620488e-05,
      "loss": 0.3791,
      "step": 3020
    },
    {
      "epoch": 0.6110102843315185,
      "grad_norm": 1.1896530389785767,
      "learning_rate": 3.472978423069168e-05,
      "loss": 0.2866,
      "step": 3030
    },
    {
      "epoch": 0.6130268199233716,
      "grad_norm": 66.7421646118164,
      "learning_rate": 3.467937084089534e-05,
      "loss": 0.304,
      "step": 3040
    },
    {
      "epoch": 0.6150433555152248,
      "grad_norm": 4.552791118621826,
      "learning_rate": 3.4628957451099016e-05,
      "loss": 0.5293,
      "step": 3050
    },
    {
      "epoch": 0.617059891107078,
      "grad_norm": 3.9856863021850586,
      "learning_rate": 3.457854406130268e-05,
      "loss": 0.6033,
      "step": 3060
    },
    {
      "epoch": 0.6190764266989313,
      "grad_norm": 2.141199827194214,
      "learning_rate": 3.4528130671506356e-05,
      "loss": 0.3466,
      "step": 3070
    },
    {
      "epoch": 0.6210929622907845,
      "grad_norm": 5.959115505218506,
      "learning_rate": 3.447771728171002e-05,
      "loss": 0.5565,
      "step": 3080
    },
    {
      "epoch": 0.6231094978826376,
      "grad_norm": 1.2630616426467896,
      "learning_rate": 3.4427303891913696e-05,
      "loss": 0.2703,
      "step": 3090
    },
    {
      "epoch": 0.6251260334744908,
      "grad_norm": 5.5470356941223145,
      "learning_rate": 3.437689050211736e-05,
      "loss": 0.5091,
      "step": 3100
    },
    {
      "epoch": 0.627142569066344,
      "grad_norm": 2.6430556774139404,
      "learning_rate": 3.432647711232103e-05,
      "loss": 0.5029,
      "step": 3110
    },
    {
      "epoch": 0.6291591046581972,
      "grad_norm": 2.37449049949646,
      "learning_rate": 3.42760637225247e-05,
      "loss": 0.418,
      "step": 3120
    },
    {
      "epoch": 0.6311756402500505,
      "grad_norm": 19.311613082885742,
      "learning_rate": 3.4225650332728375e-05,
      "loss": 0.5863,
      "step": 3130
    },
    {
      "epoch": 0.6331921758419036,
      "grad_norm": 1.6177524328231812,
      "learning_rate": 3.417523694293204e-05,
      "loss": 0.5447,
      "step": 3140
    },
    {
      "epoch": 0.6352087114337568,
      "grad_norm": 1.8636491298675537,
      "learning_rate": 3.4124823553135715e-05,
      "loss": 0.3483,
      "step": 3150
    },
    {
      "epoch": 0.63722524702561,
      "grad_norm": 12.154297828674316,
      "learning_rate": 3.407441016333938e-05,
      "loss": 0.4721,
      "step": 3160
    },
    {
      "epoch": 0.6392417826174632,
      "grad_norm": 6.363089561462402,
      "learning_rate": 3.4023996773543055e-05,
      "loss": 0.3712,
      "step": 3170
    },
    {
      "epoch": 0.6412583182093164,
      "grad_norm": 10.393641471862793,
      "learning_rate": 3.397358338374673e-05,
      "loss": 0.235,
      "step": 3180
    },
    {
      "epoch": 0.6432748538011696,
      "grad_norm": 2.0399932861328125,
      "learning_rate": 3.3923169993950394e-05,
      "loss": 0.3821,
      "step": 3190
    },
    {
      "epoch": 0.6452913893930228,
      "grad_norm": 30.656570434570312,
      "learning_rate": 3.387275660415407e-05,
      "loss": 0.4347,
      "step": 3200
    },
    {
      "epoch": 0.647307924984876,
      "grad_norm": 1.3885586261749268,
      "learning_rate": 3.3822343214357734e-05,
      "loss": 0.5509,
      "step": 3210
    },
    {
      "epoch": 0.6493244605767292,
      "grad_norm": 1.7105787992477417,
      "learning_rate": 3.377192982456141e-05,
      "loss": 0.5163,
      "step": 3220
    },
    {
      "epoch": 0.6513409961685823,
      "grad_norm": 1.7007349729537964,
      "learning_rate": 3.3721516434765074e-05,
      "loss": 0.3683,
      "step": 3230
    },
    {
      "epoch": 0.6533575317604355,
      "grad_norm": 1.0099507570266724,
      "learning_rate": 3.367110304496874e-05,
      "loss": 0.273,
      "step": 3240
    },
    {
      "epoch": 0.6553740673522888,
      "grad_norm": 12.710569381713867,
      "learning_rate": 3.3620689655172414e-05,
      "loss": 0.3519,
      "step": 3250
    },
    {
      "epoch": 0.657390602944142,
      "grad_norm": 2.1935782432556152,
      "learning_rate": 3.357027626537608e-05,
      "loss": 0.401,
      "step": 3260
    },
    {
      "epoch": 0.6594071385359952,
      "grad_norm": 42.258155822753906,
      "learning_rate": 3.351986287557975e-05,
      "loss": 0.4099,
      "step": 3270
    },
    {
      "epoch": 0.6614236741278483,
      "grad_norm": 3.593461513519287,
      "learning_rate": 3.346944948578343e-05,
      "loss": 0.2445,
      "step": 3280
    },
    {
      "epoch": 0.6634402097197015,
      "grad_norm": 1.379526972770691,
      "learning_rate": 3.341903609598709e-05,
      "loss": 0.5455,
      "step": 3290
    },
    {
      "epoch": 0.6654567453115547,
      "grad_norm": 2.735232353210449,
      "learning_rate": 3.3368622706190766e-05,
      "loss": 0.4301,
      "step": 3300
    },
    {
      "epoch": 0.667473280903408,
      "grad_norm": 2.399245500564575,
      "learning_rate": 3.331820931639444e-05,
      "loss": 0.5408,
      "step": 3310
    },
    {
      "epoch": 0.6694898164952612,
      "grad_norm": 94.6304702758789,
      "learning_rate": 3.3267795926598106e-05,
      "loss": 0.3846,
      "step": 3320
    },
    {
      "epoch": 0.6715063520871143,
      "grad_norm": 1.0916473865509033,
      "learning_rate": 3.321738253680178e-05,
      "loss": 0.4411,
      "step": 3330
    },
    {
      "epoch": 0.6735228876789675,
      "grad_norm": 17.212385177612305,
      "learning_rate": 3.3166969147005446e-05,
      "loss": 0.3607,
      "step": 3340
    },
    {
      "epoch": 0.6755394232708207,
      "grad_norm": 15.274550437927246,
      "learning_rate": 3.311655575720912e-05,
      "loss": 0.3768,
      "step": 3350
    },
    {
      "epoch": 0.677555958862674,
      "grad_norm": 1.4460645914077759,
      "learning_rate": 3.306614236741279e-05,
      "loss": 0.3542,
      "step": 3360
    },
    {
      "epoch": 0.6795724944545272,
      "grad_norm": 79.9557876586914,
      "learning_rate": 3.301572897761646e-05,
      "loss": 0.4903,
      "step": 3370
    },
    {
      "epoch": 0.6815890300463803,
      "grad_norm": 2.185232400894165,
      "learning_rate": 3.2965315587820125e-05,
      "loss": 0.5154,
      "step": 3380
    },
    {
      "epoch": 0.6836055656382335,
      "grad_norm": 1.9688677787780762,
      "learning_rate": 3.291490219802379e-05,
      "loss": 0.4287,
      "step": 3390
    },
    {
      "epoch": 0.6856221012300867,
      "grad_norm": 0.7297257781028748,
      "learning_rate": 3.2864488808227465e-05,
      "loss": 0.3355,
      "step": 3400
    },
    {
      "epoch": 0.6876386368219399,
      "grad_norm": 3.360184907913208,
      "learning_rate": 3.281407541843114e-05,
      "loss": 0.3881,
      "step": 3410
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 7.004738807678223,
      "learning_rate": 3.2763662028634805e-05,
      "loss": 0.4504,
      "step": 3420
    },
    {
      "epoch": 0.6916717080056463,
      "grad_norm": 16.89578628540039,
      "learning_rate": 3.271324863883848e-05,
      "loss": 0.4752,
      "step": 3430
    },
    {
      "epoch": 0.6936882435974995,
      "grad_norm": 1.5407166481018066,
      "learning_rate": 3.2662835249042144e-05,
      "loss": 0.3932,
      "step": 3440
    },
    {
      "epoch": 0.6957047791893527,
      "grad_norm": 17.564586639404297,
      "learning_rate": 3.261242185924582e-05,
      "loss": 0.3868,
      "step": 3450
    },
    {
      "epoch": 0.6977213147812059,
      "grad_norm": 6.171798229217529,
      "learning_rate": 3.256200846944949e-05,
      "loss": 0.3496,
      "step": 3460
    },
    {
      "epoch": 0.6997378503730591,
      "grad_norm": 34.24599075317383,
      "learning_rate": 3.251159507965316e-05,
      "loss": 0.7854,
      "step": 3470
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 63.37495803833008,
      "learning_rate": 3.246118168985683e-05,
      "loss": 0.4677,
      "step": 3480
    },
    {
      "epoch": 0.7037709215567655,
      "grad_norm": 1.2060595750808716,
      "learning_rate": 3.24107683000605e-05,
      "loss": 0.3022,
      "step": 3490
    },
    {
      "epoch": 0.7057874571486187,
      "grad_norm": 55.446327209472656,
      "learning_rate": 3.236035491026417e-05,
      "loss": 0.3439,
      "step": 3500
    },
    {
      "epoch": 0.7078039927404719,
      "grad_norm": 20.035430908203125,
      "learning_rate": 3.230994152046784e-05,
      "loss": 0.3493,
      "step": 3510
    },
    {
      "epoch": 0.7098205283323251,
      "grad_norm": 5.2553558349609375,
      "learning_rate": 3.225952813067151e-05,
      "loss": 0.2617,
      "step": 3520
    },
    {
      "epoch": 0.7118370639241782,
      "grad_norm": 1.5942171812057495,
      "learning_rate": 3.220911474087518e-05,
      "loss": 0.525,
      "step": 3530
    },
    {
      "epoch": 0.7138535995160314,
      "grad_norm": 36.698081970214844,
      "learning_rate": 3.215870135107884e-05,
      "loss": 0.3593,
      "step": 3540
    },
    {
      "epoch": 0.7158701351078847,
      "grad_norm": 3.9449713230133057,
      "learning_rate": 3.2108287961282516e-05,
      "loss": 0.5411,
      "step": 3550
    },
    {
      "epoch": 0.7178866706997379,
      "grad_norm": 44.67990493774414,
      "learning_rate": 3.205787457148619e-05,
      "loss": 0.5157,
      "step": 3560
    },
    {
      "epoch": 0.719903206291591,
      "grad_norm": 14.777212142944336,
      "learning_rate": 3.2007461181689856e-05,
      "loss": 0.4647,
      "step": 3570
    },
    {
      "epoch": 0.7219197418834442,
      "grad_norm": 3.397749423980713,
      "learning_rate": 3.195704779189353e-05,
      "loss": 0.4183,
      "step": 3580
    },
    {
      "epoch": 0.7239362774752974,
      "grad_norm": 1.4909805059432983,
      "learning_rate": 3.1906634402097196e-05,
      "loss": 0.3408,
      "step": 3590
    },
    {
      "epoch": 0.7259528130671506,
      "grad_norm": 2.525089979171753,
      "learning_rate": 3.185622101230087e-05,
      "loss": 0.4461,
      "step": 3600
    },
    {
      "epoch": 0.7279693486590039,
      "grad_norm": 15.950508117675781,
      "learning_rate": 3.180580762250454e-05,
      "loss": 0.3821,
      "step": 3610
    },
    {
      "epoch": 0.729985884250857,
      "grad_norm": 8.339688301086426,
      "learning_rate": 3.175539423270821e-05,
      "loss": 0.4436,
      "step": 3620
    },
    {
      "epoch": 0.7320024198427102,
      "grad_norm": 4.065456867218018,
      "learning_rate": 3.170498084291188e-05,
      "loss": 0.3851,
      "step": 3630
    },
    {
      "epoch": 0.7340189554345634,
      "grad_norm": 3.0345778465270996,
      "learning_rate": 3.165456745311555e-05,
      "loss": 0.3592,
      "step": 3640
    },
    {
      "epoch": 0.7360354910264166,
      "grad_norm": 1.4667459726333618,
      "learning_rate": 3.160415406331922e-05,
      "loss": 0.3976,
      "step": 3650
    },
    {
      "epoch": 0.7380520266182699,
      "grad_norm": 2.351166248321533,
      "learning_rate": 3.155374067352289e-05,
      "loss": 0.3398,
      "step": 3660
    },
    {
      "epoch": 0.740068562210123,
      "grad_norm": 41.573307037353516,
      "learning_rate": 3.1503327283726555e-05,
      "loss": 0.3527,
      "step": 3670
    },
    {
      "epoch": 0.7420850978019762,
      "grad_norm": 7.566044807434082,
      "learning_rate": 3.145291389393023e-05,
      "loss": 0.604,
      "step": 3680
    },
    {
      "epoch": 0.7441016333938294,
      "grad_norm": 41.05691909790039,
      "learning_rate": 3.1402500504133894e-05,
      "loss": 0.5142,
      "step": 3690
    },
    {
      "epoch": 0.7461181689856826,
      "grad_norm": 8.405415534973145,
      "learning_rate": 3.135208711433757e-05,
      "loss": 0.3291,
      "step": 3700
    },
    {
      "epoch": 0.7481347045775358,
      "grad_norm": 17.508304595947266,
      "learning_rate": 3.130167372454124e-05,
      "loss": 0.3276,
      "step": 3710
    },
    {
      "epoch": 0.7501512401693889,
      "grad_norm": 2.4077653884887695,
      "learning_rate": 3.125126033474491e-05,
      "loss": 0.2942,
      "step": 3720
    },
    {
      "epoch": 0.7521677757612422,
      "grad_norm": 1.5414544343948364,
      "learning_rate": 3.120084694494858e-05,
      "loss": 0.49,
      "step": 3730
    },
    {
      "epoch": 0.7541843113530954,
      "grad_norm": 7.177304267883301,
      "learning_rate": 3.115043355515225e-05,
      "loss": 0.3837,
      "step": 3740
    },
    {
      "epoch": 0.7562008469449486,
      "grad_norm": 20.148324966430664,
      "learning_rate": 3.110002016535592e-05,
      "loss": 0.6364,
      "step": 3750
    },
    {
      "epoch": 0.7582173825368018,
      "grad_norm": 11.547067642211914,
      "learning_rate": 3.1049606775559594e-05,
      "loss": 0.3835,
      "step": 3760
    },
    {
      "epoch": 0.7602339181286549,
      "grad_norm": 1.122170090675354,
      "learning_rate": 3.099919338576326e-05,
      "loss": 0.4615,
      "step": 3770
    },
    {
      "epoch": 0.7622504537205081,
      "grad_norm": 4.000256538391113,
      "learning_rate": 3.0948779995966933e-05,
      "loss": 0.3223,
      "step": 3780
    },
    {
      "epoch": 0.7642669893123614,
      "grad_norm": 4.218289852142334,
      "learning_rate": 3.08983666061706e-05,
      "loss": 0.4239,
      "step": 3790
    },
    {
      "epoch": 0.7662835249042146,
      "grad_norm": 2.2481048107147217,
      "learning_rate": 3.084795321637427e-05,
      "loss": 0.4952,
      "step": 3800
    },
    {
      "epoch": 0.7683000604960678,
      "grad_norm": 21.837682723999023,
      "learning_rate": 3.079753982657794e-05,
      "loss": 0.3234,
      "step": 3810
    },
    {
      "epoch": 0.7703165960879209,
      "grad_norm": 1.9931092262268066,
      "learning_rate": 3.0747126436781606e-05,
      "loss": 0.3958,
      "step": 3820
    },
    {
      "epoch": 0.7723331316797741,
      "grad_norm": 21.098892211914062,
      "learning_rate": 3.069671304698528e-05,
      "loss": 0.2529,
      "step": 3830
    },
    {
      "epoch": 0.7743496672716274,
      "grad_norm": 5.286548614501953,
      "learning_rate": 3.0646299657188946e-05,
      "loss": 0.3327,
      "step": 3840
    },
    {
      "epoch": 0.7763662028634806,
      "grad_norm": 16.509502410888672,
      "learning_rate": 3.059588626739262e-05,
      "loss": 0.5478,
      "step": 3850
    },
    {
      "epoch": 0.7783827384553338,
      "grad_norm": 79.84529113769531,
      "learning_rate": 3.054547287759629e-05,
      "loss": 0.5072,
      "step": 3860
    },
    {
      "epoch": 0.7803992740471869,
      "grad_norm": 72.5807113647461,
      "learning_rate": 3.049505948779996e-05,
      "loss": 0.2909,
      "step": 3870
    },
    {
      "epoch": 0.7824158096390401,
      "grad_norm": 56.69296646118164,
      "learning_rate": 3.0444646098003632e-05,
      "loss": 0.3432,
      "step": 3880
    },
    {
      "epoch": 0.7844323452308933,
      "grad_norm": 11.137812614440918,
      "learning_rate": 3.03942327082073e-05,
      "loss": 0.3124,
      "step": 3890
    },
    {
      "epoch": 0.7864488808227466,
      "grad_norm": 9.679248809814453,
      "learning_rate": 3.0343819318410972e-05,
      "loss": 0.4431,
      "step": 3900
    },
    {
      "epoch": 0.7884654164145997,
      "grad_norm": 40.30107498168945,
      "learning_rate": 3.029340592861464e-05,
      "loss": 0.4265,
      "step": 3910
    },
    {
      "epoch": 0.7904819520064529,
      "grad_norm": 9.52298641204834,
      "learning_rate": 3.024299253881831e-05,
      "loss": 0.451,
      "step": 3920
    },
    {
      "epoch": 0.7924984875983061,
      "grad_norm": 2.199306011199951,
      "learning_rate": 3.019257914902198e-05,
      "loss": 0.6213,
      "step": 3930
    },
    {
      "epoch": 0.7945150231901593,
      "grad_norm": 10.936162948608398,
      "learning_rate": 3.0142165759225648e-05,
      "loss": 0.3692,
      "step": 3940
    },
    {
      "epoch": 0.7965315587820125,
      "grad_norm": 2.4107847213745117,
      "learning_rate": 3.009175236942932e-05,
      "loss": 0.3747,
      "step": 3950
    },
    {
      "epoch": 0.7985480943738656,
      "grad_norm": 1.1782046556472778,
      "learning_rate": 3.0041338979632994e-05,
      "loss": 0.3237,
      "step": 3960
    },
    {
      "epoch": 0.8005646299657189,
      "grad_norm": 23.088356018066406,
      "learning_rate": 2.999092558983666e-05,
      "loss": 0.4397,
      "step": 3970
    },
    {
      "epoch": 0.8025811655575721,
      "grad_norm": 1.8625996112823486,
      "learning_rate": 2.9940512200040334e-05,
      "loss": 0.4177,
      "step": 3980
    },
    {
      "epoch": 0.8045977011494253,
      "grad_norm": 20.47756004333496,
      "learning_rate": 2.9890098810244004e-05,
      "loss": 0.4583,
      "step": 3990
    },
    {
      "epoch": 0.8066142367412785,
      "grad_norm": 1.4917628765106201,
      "learning_rate": 2.983968542044767e-05,
      "loss": 0.4175,
      "step": 4000
    },
    {
      "epoch": 0.8086307723331316,
      "grad_norm": 9.270242691040039,
      "learning_rate": 2.9789272030651344e-05,
      "loss": 0.5008,
      "step": 4010
    },
    {
      "epoch": 0.8106473079249849,
      "grad_norm": 2.2230188846588135,
      "learning_rate": 2.973885864085501e-05,
      "loss": 0.3779,
      "step": 4020
    },
    {
      "epoch": 0.8126638435168381,
      "grad_norm": 1.8047722578048706,
      "learning_rate": 2.9688445251058683e-05,
      "loss": 0.4024,
      "step": 4030
    },
    {
      "epoch": 0.8146803791086913,
      "grad_norm": 3.2126317024230957,
      "learning_rate": 2.9638031861262357e-05,
      "loss": 0.2477,
      "step": 4040
    },
    {
      "epoch": 0.8166969147005445,
      "grad_norm": 3.2873899936676025,
      "learning_rate": 2.9587618471466023e-05,
      "loss": 0.4157,
      "step": 4050
    },
    {
      "epoch": 0.8187134502923976,
      "grad_norm": 4.268347263336182,
      "learning_rate": 2.9537205081669693e-05,
      "loss": 0.4414,
      "step": 4060
    },
    {
      "epoch": 0.8207299858842508,
      "grad_norm": 12.831602096557617,
      "learning_rate": 2.948679169187336e-05,
      "loss": 0.4818,
      "step": 4070
    },
    {
      "epoch": 0.822746521476104,
      "grad_norm": 2.3479549884796143,
      "learning_rate": 2.9436378302077033e-05,
      "loss": 0.3331,
      "step": 4080
    },
    {
      "epoch": 0.8247630570679573,
      "grad_norm": 7.8531670570373535,
      "learning_rate": 2.9385964912280706e-05,
      "loss": 0.385,
      "step": 4090
    },
    {
      "epoch": 0.8267795926598105,
      "grad_norm": 1.4033085107803345,
      "learning_rate": 2.9335551522484372e-05,
      "loss": 0.2961,
      "step": 4100
    },
    {
      "epoch": 0.8287961282516636,
      "grad_norm": 1.9787694215774536,
      "learning_rate": 2.9285138132688046e-05,
      "loss": 0.3346,
      "step": 4110
    },
    {
      "epoch": 0.8308126638435168,
      "grad_norm": 1.3026220798492432,
      "learning_rate": 2.9234724742891712e-05,
      "loss": 0.2741,
      "step": 4120
    },
    {
      "epoch": 0.83282919943537,
      "grad_norm": 1.3435832262039185,
      "learning_rate": 2.9184311353095382e-05,
      "loss": 0.3083,
      "step": 4130
    },
    {
      "epoch": 0.8348457350272233,
      "grad_norm": 13.994401931762695,
      "learning_rate": 2.9133897963299055e-05,
      "loss": 0.3991,
      "step": 4140
    },
    {
      "epoch": 0.8368622706190765,
      "grad_norm": 5.123234748840332,
      "learning_rate": 2.9083484573502722e-05,
      "loss": 0.4253,
      "step": 4150
    },
    {
      "epoch": 0.8388788062109296,
      "grad_norm": 2.3133037090301514,
      "learning_rate": 2.9033071183706395e-05,
      "loss": 0.5331,
      "step": 4160
    },
    {
      "epoch": 0.8408953418027828,
      "grad_norm": 3.9698431491851807,
      "learning_rate": 2.898265779391006e-05,
      "loss": 0.2206,
      "step": 4170
    },
    {
      "epoch": 0.842911877394636,
      "grad_norm": 8.853059768676758,
      "learning_rate": 2.8932244404113735e-05,
      "loss": 0.6301,
      "step": 4180
    },
    {
      "epoch": 0.8449284129864892,
      "grad_norm": 2.9736456871032715,
      "learning_rate": 2.8881831014317408e-05,
      "loss": 0.3988,
      "step": 4190
    },
    {
      "epoch": 0.8469449485783425,
      "grad_norm": 9.425455093383789,
      "learning_rate": 2.8831417624521075e-05,
      "loss": 0.3905,
      "step": 4200
    },
    {
      "epoch": 0.8489614841701956,
      "grad_norm": 1.4506986141204834,
      "learning_rate": 2.8781004234724744e-05,
      "loss": 0.2585,
      "step": 4210
    },
    {
      "epoch": 0.8509780197620488,
      "grad_norm": 9.198850631713867,
      "learning_rate": 2.873059084492841e-05,
      "loss": 0.3687,
      "step": 4220
    },
    {
      "epoch": 0.852994555353902,
      "grad_norm": 14.52780532836914,
      "learning_rate": 2.8680177455132084e-05,
      "loss": 0.455,
      "step": 4230
    },
    {
      "epoch": 0.8550110909457552,
      "grad_norm": 2.1668128967285156,
      "learning_rate": 2.8629764065335757e-05,
      "loss": 0.3945,
      "step": 4240
    },
    {
      "epoch": 0.8570276265376083,
      "grad_norm": 6.11374044418335,
      "learning_rate": 2.8579350675539424e-05,
      "loss": 0.4899,
      "step": 4250
    },
    {
      "epoch": 0.8590441621294616,
      "grad_norm": 2.441507577896118,
      "learning_rate": 2.8528937285743097e-05,
      "loss": 0.3703,
      "step": 4260
    },
    {
      "epoch": 0.8610606977213148,
      "grad_norm": 1.6464529037475586,
      "learning_rate": 2.8478523895946764e-05,
      "loss": 0.3703,
      "step": 4270
    },
    {
      "epoch": 0.863077233313168,
      "grad_norm": 1.1298140287399292,
      "learning_rate": 2.8428110506150433e-05,
      "loss": 0.4171,
      "step": 4280
    },
    {
      "epoch": 0.8650937689050212,
      "grad_norm": 11.370234489440918,
      "learning_rate": 2.8377697116354107e-05,
      "loss": 0.3956,
      "step": 4290
    },
    {
      "epoch": 0.8671103044968743,
      "grad_norm": 3.776796579360962,
      "learning_rate": 2.8327283726557773e-05,
      "loss": 0.3875,
      "step": 4300
    },
    {
      "epoch": 0.8691268400887275,
      "grad_norm": 1.9049439430236816,
      "learning_rate": 2.8276870336761446e-05,
      "loss": 0.5262,
      "step": 4310
    },
    {
      "epoch": 0.8711433756805808,
      "grad_norm": 3.7625925540924072,
      "learning_rate": 2.8226456946965113e-05,
      "loss": 0.4052,
      "step": 4320
    },
    {
      "epoch": 0.873159911272434,
      "grad_norm": 1.2838000059127808,
      "learning_rate": 2.8176043557168786e-05,
      "loss": 0.3592,
      "step": 4330
    },
    {
      "epoch": 0.8751764468642872,
      "grad_norm": 19.944725036621094,
      "learning_rate": 2.8125630167372456e-05,
      "loss": 0.3375,
      "step": 4340
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 10.088780403137207,
      "learning_rate": 2.8075216777576126e-05,
      "loss": 0.503,
      "step": 4350
    },
    {
      "epoch": 0.8792095180479935,
      "grad_norm": 4.497416973114014,
      "learning_rate": 2.8024803387779796e-05,
      "loss": 0.3746,
      "step": 4360
    },
    {
      "epoch": 0.8812260536398467,
      "grad_norm": 1.4661599397659302,
      "learning_rate": 2.7974389997983462e-05,
      "loss": 0.3887,
      "step": 4370
    },
    {
      "epoch": 0.8832425892317,
      "grad_norm": 43.94038772583008,
      "learning_rate": 2.7923976608187135e-05,
      "loss": 0.5104,
      "step": 4380
    },
    {
      "epoch": 0.8852591248235532,
      "grad_norm": 4.581221580505371,
      "learning_rate": 2.787356321839081e-05,
      "loss": 0.4587,
      "step": 4390
    },
    {
      "epoch": 0.8872756604154063,
      "grad_norm": 0.8618960976600647,
      "learning_rate": 2.7823149828594475e-05,
      "loss": 0.5352,
      "step": 4400
    },
    {
      "epoch": 0.8892921960072595,
      "grad_norm": 8.428305625915527,
      "learning_rate": 2.777273643879815e-05,
      "loss": 0.3958,
      "step": 4410
    },
    {
      "epoch": 0.8913087315991127,
      "grad_norm": 1.0254237651824951,
      "learning_rate": 2.7722323049001815e-05,
      "loss": 0.3939,
      "step": 4420
    },
    {
      "epoch": 0.8933252671909659,
      "grad_norm": 2.1114864349365234,
      "learning_rate": 2.7671909659205485e-05,
      "loss": 0.431,
      "step": 4430
    },
    {
      "epoch": 0.8953418027828192,
      "grad_norm": 18.410612106323242,
      "learning_rate": 2.7621496269409158e-05,
      "loss": 0.4612,
      "step": 4440
    },
    {
      "epoch": 0.8973583383746723,
      "grad_norm": 50.5177001953125,
      "learning_rate": 2.7571082879612825e-05,
      "loss": 0.3306,
      "step": 4450
    },
    {
      "epoch": 0.8993748739665255,
      "grad_norm": 33.30152130126953,
      "learning_rate": 2.7520669489816498e-05,
      "loss": 0.4128,
      "step": 4460
    },
    {
      "epoch": 0.9013914095583787,
      "grad_norm": 3.3255350589752197,
      "learning_rate": 2.7470256100020164e-05,
      "loss": 0.3971,
      "step": 4470
    },
    {
      "epoch": 0.9034079451502319,
      "grad_norm": 1.2428134679794312,
      "learning_rate": 2.7419842710223838e-05,
      "loss": 0.3302,
      "step": 4480
    },
    {
      "epoch": 0.9054244807420851,
      "grad_norm": 0.9239177703857422,
      "learning_rate": 2.7369429320427507e-05,
      "loss": 0.3811,
      "step": 4490
    },
    {
      "epoch": 0.9074410163339383,
      "grad_norm": 1.010628342628479,
      "learning_rate": 2.7319015930631174e-05,
      "loss": 0.3804,
      "step": 4500
    },
    {
      "epoch": 0.9094575519257915,
      "grad_norm": 5.448174953460693,
      "learning_rate": 2.7268602540834847e-05,
      "loss": 0.3687,
      "step": 4510
    },
    {
      "epoch": 0.9114740875176447,
      "grad_norm": 36.01120376586914,
      "learning_rate": 2.7218189151038514e-05,
      "loss": 0.3043,
      "step": 4520
    },
    {
      "epoch": 0.9134906231094979,
      "grad_norm": 43.696495056152344,
      "learning_rate": 2.7167775761242187e-05,
      "loss": 0.3665,
      "step": 4530
    },
    {
      "epoch": 0.9155071587013511,
      "grad_norm": 12.40044116973877,
      "learning_rate": 2.711736237144586e-05,
      "loss": 0.325,
      "step": 4540
    },
    {
      "epoch": 0.9175236942932042,
      "grad_norm": 22.231863021850586,
      "learning_rate": 2.7066948981649527e-05,
      "loss": 0.3464,
      "step": 4550
    },
    {
      "epoch": 0.9195402298850575,
      "grad_norm": 6.6040472984313965,
      "learning_rate": 2.70165355918532e-05,
      "loss": 0.3773,
      "step": 4560
    },
    {
      "epoch": 0.9215567654769107,
      "grad_norm": 6.148664474487305,
      "learning_rate": 2.6966122202056866e-05,
      "loss": 0.3659,
      "step": 4570
    },
    {
      "epoch": 0.9235733010687639,
      "grad_norm": 3.721264362335205,
      "learning_rate": 2.6915708812260536e-05,
      "loss": 0.5939,
      "step": 4580
    },
    {
      "epoch": 0.925589836660617,
      "grad_norm": 13.008739471435547,
      "learning_rate": 2.686529542246421e-05,
      "loss": 0.3432,
      "step": 4590
    },
    {
      "epoch": 0.9276063722524702,
      "grad_norm": 23.82500457763672,
      "learning_rate": 2.6814882032667876e-05,
      "loss": 0.4741,
      "step": 4600
    },
    {
      "epoch": 0.9296229078443234,
      "grad_norm": 141.23651123046875,
      "learning_rate": 2.676446864287155e-05,
      "loss": 0.5345,
      "step": 4610
    },
    {
      "epoch": 0.9316394434361767,
      "grad_norm": 1.1648499965667725,
      "learning_rate": 2.6714055253075216e-05,
      "loss": 0.2627,
      "step": 4620
    },
    {
      "epoch": 0.9336559790280299,
      "grad_norm": 6.88178014755249,
      "learning_rate": 2.666364186327889e-05,
      "loss": 0.2639,
      "step": 4630
    },
    {
      "epoch": 0.935672514619883,
      "grad_norm": 3.0843024253845215,
      "learning_rate": 2.661322847348256e-05,
      "loss": 0.7079,
      "step": 4640
    },
    {
      "epoch": 0.9376890502117362,
      "grad_norm": 9.449329376220703,
      "learning_rate": 2.6562815083686225e-05,
      "loss": 0.2991,
      "step": 4650
    },
    {
      "epoch": 0.9397055858035894,
      "grad_norm": 492.8753662109375,
      "learning_rate": 2.65124016938899e-05,
      "loss": 0.4022,
      "step": 4660
    },
    {
      "epoch": 0.9417221213954426,
      "grad_norm": 14.758708000183105,
      "learning_rate": 2.6461988304093572e-05,
      "loss": 0.5419,
      "step": 4670
    },
    {
      "epoch": 0.9437386569872959,
      "grad_norm": 3.836827039718628,
      "learning_rate": 2.6411574914297238e-05,
      "loss": 0.3227,
      "step": 4680
    },
    {
      "epoch": 0.945755192579149,
      "grad_norm": 4.4470744132995605,
      "learning_rate": 2.636116152450091e-05,
      "loss": 0.4597,
      "step": 4690
    },
    {
      "epoch": 0.9477717281710022,
      "grad_norm": 67.58587646484375,
      "learning_rate": 2.6310748134704578e-05,
      "loss": 0.5096,
      "step": 4700
    },
    {
      "epoch": 0.9497882637628554,
      "grad_norm": 8.982855796813965,
      "learning_rate": 2.6260334744908248e-05,
      "loss": 0.3454,
      "step": 4710
    },
    {
      "epoch": 0.9518047993547086,
      "grad_norm": 1.546796202659607,
      "learning_rate": 2.620992135511192e-05,
      "loss": 0.3368,
      "step": 4720
    },
    {
      "epoch": 0.9538213349465618,
      "grad_norm": 6.241573333740234,
      "learning_rate": 2.6159507965315588e-05,
      "loss": 0.3118,
      "step": 4730
    },
    {
      "epoch": 0.955837870538415,
      "grad_norm": 3.8422064781188965,
      "learning_rate": 2.610909457551926e-05,
      "loss": 0.2897,
      "step": 4740
    },
    {
      "epoch": 0.9578544061302682,
      "grad_norm": 4.924294471740723,
      "learning_rate": 2.6058681185722927e-05,
      "loss": 0.3204,
      "step": 4750
    },
    {
      "epoch": 0.9598709417221214,
      "grad_norm": 8.079270362854004,
      "learning_rate": 2.60082677959266e-05,
      "loss": 0.394,
      "step": 4760
    },
    {
      "epoch": 0.9618874773139746,
      "grad_norm": 28.95589256286621,
      "learning_rate": 2.595785440613027e-05,
      "loss": 0.4566,
      "step": 4770
    },
    {
      "epoch": 0.9639040129058278,
      "grad_norm": 2.60673189163208,
      "learning_rate": 2.590744101633394e-05,
      "loss": 0.4204,
      "step": 4780
    },
    {
      "epoch": 0.9659205484976809,
      "grad_norm": 29.111398696899414,
      "learning_rate": 2.585702762653761e-05,
      "loss": 0.3563,
      "step": 4790
    },
    {
      "epoch": 0.9679370840895342,
      "grad_norm": 16.976490020751953,
      "learning_rate": 2.5806614236741277e-05,
      "loss": 0.2883,
      "step": 4800
    },
    {
      "epoch": 0.9699536196813874,
      "grad_norm": 3.9103331565856934,
      "learning_rate": 2.575620084694495e-05,
      "loss": 0.3624,
      "step": 4810
    },
    {
      "epoch": 0.9719701552732406,
      "grad_norm": 29.711332321166992,
      "learning_rate": 2.5705787457148623e-05,
      "loss": 0.5197,
      "step": 4820
    },
    {
      "epoch": 0.9739866908650938,
      "grad_norm": 8.089860916137695,
      "learning_rate": 2.565537406735229e-05,
      "loss": 0.4031,
      "step": 4830
    },
    {
      "epoch": 0.9760032264569469,
      "grad_norm": 5.372949123382568,
      "learning_rate": 2.5604960677555963e-05,
      "loss": 0.4768,
      "step": 4840
    },
    {
      "epoch": 0.9780197620488001,
      "grad_norm": 31.09061050415039,
      "learning_rate": 2.555454728775963e-05,
      "loss": 0.4562,
      "step": 4850
    },
    {
      "epoch": 0.9800362976406534,
      "grad_norm": 1.0550932884216309,
      "learning_rate": 2.55041338979633e-05,
      "loss": 0.3333,
      "step": 4860
    },
    {
      "epoch": 0.9820528332325066,
      "grad_norm": 14.580116271972656,
      "learning_rate": 2.5453720508166972e-05,
      "loss": 0.3934,
      "step": 4870
    },
    {
      "epoch": 0.9840693688243598,
      "grad_norm": 7.829423904418945,
      "learning_rate": 2.540330711837064e-05,
      "loss": 0.4163,
      "step": 4880
    },
    {
      "epoch": 0.9860859044162129,
      "grad_norm": 1.585466742515564,
      "learning_rate": 2.5352893728574312e-05,
      "loss": 0.3756,
      "step": 4890
    },
    {
      "epoch": 0.9881024400080661,
      "grad_norm": 39.143638610839844,
      "learning_rate": 2.530248033877798e-05,
      "loss": 0.4343,
      "step": 4900
    },
    {
      "epoch": 0.9901189755999193,
      "grad_norm": 1.165976643562317,
      "learning_rate": 2.5252066948981652e-05,
      "loss": 0.4984,
      "step": 4910
    },
    {
      "epoch": 0.9921355111917726,
      "grad_norm": 0.9850594401359558,
      "learning_rate": 2.5201653559185322e-05,
      "loss": 0.3976,
      "step": 4920
    },
    {
      "epoch": 0.9941520467836257,
      "grad_norm": 21.779722213745117,
      "learning_rate": 2.5151240169388988e-05,
      "loss": 0.4816,
      "step": 4930
    },
    {
      "epoch": 0.9961685823754789,
      "grad_norm": 2.683067560195923,
      "learning_rate": 2.510082677959266e-05,
      "loss": 0.5152,
      "step": 4940
    },
    {
      "epoch": 0.9981851179673321,
      "grad_norm": 1.0628340244293213,
      "learning_rate": 2.5050413389796328e-05,
      "loss": 0.4292,
      "step": 4950
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.42764294147491455,
      "eval_runtime": 590.9975,
      "eval_samples_per_second": 16.78,
      "eval_steps_per_second": 2.098,
      "step": 4959
    },
    {
      "epoch": 1.0002016535591853,
      "grad_norm": 2.2139248847961426,
      "learning_rate": 2.5e-05,
      "loss": 0.2689,
      "step": 4960
    },
    {
      "epoch": 1.0022181891510384,
      "grad_norm": 0.9638294577598572,
      "learning_rate": 2.494958661020367e-05,
      "loss": 0.2585,
      "step": 4970
    },
    {
      "epoch": 1.0042347247428918,
      "grad_norm": 0.7001004815101624,
      "learning_rate": 2.489917322040734e-05,
      "loss": 0.2512,
      "step": 4980
    },
    {
      "epoch": 1.0062512603347449,
      "grad_norm": 2.6223127841949463,
      "learning_rate": 2.4848759830611014e-05,
      "loss": 0.3839,
      "step": 4990
    },
    {
      "epoch": 1.0082677959265982,
      "grad_norm": 22.584806442260742,
      "learning_rate": 2.479834644081468e-05,
      "loss": 0.3192,
      "step": 5000
    },
    {
      "epoch": 1.0102843315184513,
      "grad_norm": 35.26829528808594,
      "learning_rate": 2.474793305101835e-05,
      "loss": 0.317,
      "step": 5010
    },
    {
      "epoch": 1.0123008671103044,
      "grad_norm": 6.580564975738525,
      "learning_rate": 2.469751966122202e-05,
      "loss": 0.5019,
      "step": 5020
    },
    {
      "epoch": 1.0143174027021578,
      "grad_norm": 8.41047477722168,
      "learning_rate": 2.464710627142569e-05,
      "loss": 0.2689,
      "step": 5030
    },
    {
      "epoch": 1.0163339382940109,
      "grad_norm": 21.495586395263672,
      "learning_rate": 2.4596692881629364e-05,
      "loss": 0.4589,
      "step": 5040
    },
    {
      "epoch": 1.0183504738858642,
      "grad_norm": 132.2487335205078,
      "learning_rate": 2.4546279491833033e-05,
      "loss": 0.4221,
      "step": 5050
    },
    {
      "epoch": 1.0203670094777173,
      "grad_norm": 1.0418338775634766,
      "learning_rate": 2.4495866102036703e-05,
      "loss": 0.3143,
      "step": 5060
    },
    {
      "epoch": 1.0223835450695704,
      "grad_norm": 8.428088188171387,
      "learning_rate": 2.4445452712240373e-05,
      "loss": 0.4269,
      "step": 5070
    },
    {
      "epoch": 1.0244000806614237,
      "grad_norm": 0.6356472969055176,
      "learning_rate": 2.439503932244404e-05,
      "loss": 0.2521,
      "step": 5080
    },
    {
      "epoch": 1.0264166162532768,
      "grad_norm": 24.225261688232422,
      "learning_rate": 2.4344625932647713e-05,
      "loss": 0.1665,
      "step": 5090
    },
    {
      "epoch": 1.02843315184513,
      "grad_norm": 18.37202262878418,
      "learning_rate": 2.4294212542851383e-05,
      "loss": 0.2209,
      "step": 5100
    },
    {
      "epoch": 1.0304496874369833,
      "grad_norm": 11.759532928466797,
      "learning_rate": 2.4243799153055053e-05,
      "loss": 0.4909,
      "step": 5110
    },
    {
      "epoch": 1.0324662230288364,
      "grad_norm": 1.2902809381484985,
      "learning_rate": 2.4193385763258722e-05,
      "loss": 0.3695,
      "step": 5120
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.9439727663993835,
      "learning_rate": 2.4142972373462396e-05,
      "loss": 0.3491,
      "step": 5130
    },
    {
      "epoch": 1.0364992942125428,
      "grad_norm": 0.4139699339866638,
      "learning_rate": 2.4092558983666062e-05,
      "loss": 0.1916,
      "step": 5140
    },
    {
      "epoch": 1.038515829804396,
      "grad_norm": 0.7562927007675171,
      "learning_rate": 2.4042145593869732e-05,
      "loss": 0.4476,
      "step": 5150
    },
    {
      "epoch": 1.0405323653962493,
      "grad_norm": 0.9111061692237854,
      "learning_rate": 2.3991732204073402e-05,
      "loss": 0.1792,
      "step": 5160
    },
    {
      "epoch": 1.0425489009881024,
      "grad_norm": 2.1121277809143066,
      "learning_rate": 2.3941318814277072e-05,
      "loss": 0.3426,
      "step": 5170
    },
    {
      "epoch": 1.0445654365799557,
      "grad_norm": 25.700359344482422,
      "learning_rate": 2.3890905424480745e-05,
      "loss": 0.4792,
      "step": 5180
    },
    {
      "epoch": 1.0465819721718088,
      "grad_norm": 8.627209663391113,
      "learning_rate": 2.3840492034684415e-05,
      "loss": 0.4359,
      "step": 5190
    },
    {
      "epoch": 1.048598507763662,
      "grad_norm": 2.443127155303955,
      "learning_rate": 2.3790078644888085e-05,
      "loss": 0.5193,
      "step": 5200
    },
    {
      "epoch": 1.0506150433555153,
      "grad_norm": 1.1162970066070557,
      "learning_rate": 2.3739665255091755e-05,
      "loss": 0.3302,
      "step": 5210
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 1.873147964477539,
      "learning_rate": 2.368925186529542e-05,
      "loss": 0.3711,
      "step": 5220
    },
    {
      "epoch": 1.0546481145392217,
      "grad_norm": 2.2951436042785645,
      "learning_rate": 2.3638838475499094e-05,
      "loss": 0.4128,
      "step": 5230
    },
    {
      "epoch": 1.0566646501310748,
      "grad_norm": 1.7059367895126343,
      "learning_rate": 2.3588425085702764e-05,
      "loss": 0.3148,
      "step": 5240
    },
    {
      "epoch": 1.058681185722928,
      "grad_norm": 1.093169927597046,
      "learning_rate": 2.3538011695906434e-05,
      "loss": 0.2175,
      "step": 5250
    },
    {
      "epoch": 1.0606977213147812,
      "grad_norm": 0.8581798076629639,
      "learning_rate": 2.3487598306110104e-05,
      "loss": 0.2804,
      "step": 5260
    },
    {
      "epoch": 1.0627142569066343,
      "grad_norm": 26.397733688354492,
      "learning_rate": 2.3437184916313774e-05,
      "loss": 0.4586,
      "step": 5270
    },
    {
      "epoch": 1.0647307924984877,
      "grad_norm": 0.5785881280899048,
      "learning_rate": 2.3386771526517444e-05,
      "loss": 0.3399,
      "step": 5280
    },
    {
      "epoch": 1.0667473280903408,
      "grad_norm": 0.691198468208313,
      "learning_rate": 2.3336358136721114e-05,
      "loss": 0.1696,
      "step": 5290
    },
    {
      "epoch": 1.068763863682194,
      "grad_norm": 36.627140045166016,
      "learning_rate": 2.3285944746924783e-05,
      "loss": 0.2978,
      "step": 5300
    },
    {
      "epoch": 1.0707803992740472,
      "grad_norm": 8.311202049255371,
      "learning_rate": 2.3235531357128453e-05,
      "loss": 0.3203,
      "step": 5310
    },
    {
      "epoch": 1.0727969348659003,
      "grad_norm": 1.2762138843536377,
      "learning_rate": 2.3185117967332123e-05,
      "loss": 0.2457,
      "step": 5320
    },
    {
      "epoch": 1.0748134704577537,
      "grad_norm": 93.72018432617188,
      "learning_rate": 2.3134704577535796e-05,
      "loss": 0.3383,
      "step": 5330
    },
    {
      "epoch": 1.0768300060496068,
      "grad_norm": 0.43375644087791443,
      "learning_rate": 2.3084291187739466e-05,
      "loss": 0.3892,
      "step": 5340
    },
    {
      "epoch": 1.0788465416414599,
      "grad_norm": 70.61473846435547,
      "learning_rate": 2.3033877797943136e-05,
      "loss": 0.2361,
      "step": 5350
    },
    {
      "epoch": 1.0808630772333132,
      "grad_norm": 4.7424235343933105,
      "learning_rate": 2.2983464408146803e-05,
      "loss": 0.2301,
      "step": 5360
    },
    {
      "epoch": 1.0828796128251663,
      "grad_norm": 2.7197623252868652,
      "learning_rate": 2.2933051018350472e-05,
      "loss": 0.285,
      "step": 5370
    },
    {
      "epoch": 1.0848961484170196,
      "grad_norm": 2.209172487258911,
      "learning_rate": 2.2882637628554146e-05,
      "loss": 0.357,
      "step": 5380
    },
    {
      "epoch": 1.0869126840088728,
      "grad_norm": 117.82770538330078,
      "learning_rate": 2.2832224238757816e-05,
      "loss": 0.4277,
      "step": 5390
    },
    {
      "epoch": 1.0889292196007259,
      "grad_norm": 2.557225465774536,
      "learning_rate": 2.2781810848961485e-05,
      "loss": 0.4348,
      "step": 5400
    },
    {
      "epoch": 1.0909457551925792,
      "grad_norm": 0.7420814037322998,
      "learning_rate": 2.2731397459165155e-05,
      "loss": 0.4631,
      "step": 5410
    },
    {
      "epoch": 1.0929622907844323,
      "grad_norm": 0.9698233604431152,
      "learning_rate": 2.2680984069368825e-05,
      "loss": 0.3012,
      "step": 5420
    },
    {
      "epoch": 1.0949788263762856,
      "grad_norm": 0.9353955984115601,
      "learning_rate": 2.2630570679572495e-05,
      "loss": 0.2937,
      "step": 5430
    },
    {
      "epoch": 1.0969953619681387,
      "grad_norm": 1.112436056137085,
      "learning_rate": 2.2580157289776165e-05,
      "loss": 0.3584,
      "step": 5440
    },
    {
      "epoch": 1.0990118975599918,
      "grad_norm": 2.496649980545044,
      "learning_rate": 2.2529743899979835e-05,
      "loss": 0.479,
      "step": 5450
    },
    {
      "epoch": 1.1010284331518452,
      "grad_norm": 1.7048125267028809,
      "learning_rate": 2.2479330510183505e-05,
      "loss": 0.481,
      "step": 5460
    },
    {
      "epoch": 1.1030449687436983,
      "grad_norm": 7.352989196777344,
      "learning_rate": 2.2428917120387178e-05,
      "loss": 0.5246,
      "step": 5470
    },
    {
      "epoch": 1.1050615043355516,
      "grad_norm": 3.163463592529297,
      "learning_rate": 2.2378503730590848e-05,
      "loss": 0.2348,
      "step": 5480
    },
    {
      "epoch": 1.1070780399274047,
      "grad_norm": 13.81281566619873,
      "learning_rate": 2.2328090340794518e-05,
      "loss": 0.4825,
      "step": 5490
    },
    {
      "epoch": 1.1090945755192578,
      "grad_norm": 2.627685308456421,
      "learning_rate": 2.2277676950998187e-05,
      "loss": 0.3068,
      "step": 5500
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 4.427319526672363,
      "learning_rate": 2.2227263561201854e-05,
      "loss": 0.2225,
      "step": 5510
    },
    {
      "epoch": 1.1131276467029643,
      "grad_norm": 3.199488639831543,
      "learning_rate": 2.2176850171405527e-05,
      "loss": 0.1898,
      "step": 5520
    },
    {
      "epoch": 1.1151441822948176,
      "grad_norm": 9.204119682312012,
      "learning_rate": 2.2126436781609197e-05,
      "loss": 0.3962,
      "step": 5530
    },
    {
      "epoch": 1.1171607178866707,
      "grad_norm": 7.768362045288086,
      "learning_rate": 2.2076023391812867e-05,
      "loss": 0.4796,
      "step": 5540
    },
    {
      "epoch": 1.1191772534785238,
      "grad_norm": 1.225816011428833,
      "learning_rate": 2.2025610002016537e-05,
      "loss": 0.3313,
      "step": 5550
    },
    {
      "epoch": 1.1211937890703771,
      "grad_norm": 1.065701961517334,
      "learning_rate": 2.1975196612220207e-05,
      "loss": 0.417,
      "step": 5560
    },
    {
      "epoch": 1.1232103246622303,
      "grad_norm": 1.366222858428955,
      "learning_rate": 2.1924783222423877e-05,
      "loss": 0.3382,
      "step": 5570
    },
    {
      "epoch": 1.1252268602540836,
      "grad_norm": 0.971150279045105,
      "learning_rate": 2.1874369832627546e-05,
      "loss": 0.167,
      "step": 5580
    },
    {
      "epoch": 1.1272433958459367,
      "grad_norm": 1.6572000980377197,
      "learning_rate": 2.1823956442831216e-05,
      "loss": 0.306,
      "step": 5590
    },
    {
      "epoch": 1.1292599314377898,
      "grad_norm": 180.40625,
      "learning_rate": 2.1773543053034886e-05,
      "loss": 0.1717,
      "step": 5600
    },
    {
      "epoch": 1.1312764670296431,
      "grad_norm": 1.0858266353607178,
      "learning_rate": 2.1723129663238556e-05,
      "loss": 0.2027,
      "step": 5610
    },
    {
      "epoch": 1.1332930026214962,
      "grad_norm": 33.58665084838867,
      "learning_rate": 2.167271627344223e-05,
      "loss": 0.2371,
      "step": 5620
    },
    {
      "epoch": 1.1353095382133493,
      "grad_norm": 27.019180297851562,
      "learning_rate": 2.16223028836459e-05,
      "loss": 0.6259,
      "step": 5630
    },
    {
      "epoch": 1.1373260738052027,
      "grad_norm": 0.8110865354537964,
      "learning_rate": 2.157188949384957e-05,
      "loss": 0.5528,
      "step": 5640
    },
    {
      "epoch": 1.1393426093970558,
      "grad_norm": 95.5044174194336,
      "learning_rate": 2.1521476104053235e-05,
      "loss": 0.474,
      "step": 5650
    },
    {
      "epoch": 1.1413591449889091,
      "grad_norm": 0.7075589299201965,
      "learning_rate": 2.1471062714256905e-05,
      "loss": 0.3296,
      "step": 5660
    },
    {
      "epoch": 1.1433756805807622,
      "grad_norm": 11.574212074279785,
      "learning_rate": 2.142064932446058e-05,
      "loss": 0.234,
      "step": 5670
    },
    {
      "epoch": 1.1453922161726156,
      "grad_norm": 1.1902211904525757,
      "learning_rate": 2.137023593466425e-05,
      "loss": 0.1902,
      "step": 5680
    },
    {
      "epoch": 1.1474087517644687,
      "grad_norm": 39.003108978271484,
      "learning_rate": 2.1319822544867918e-05,
      "loss": 0.5995,
      "step": 5690
    },
    {
      "epoch": 1.1494252873563218,
      "grad_norm": 0.9799922108650208,
      "learning_rate": 2.1269409155071588e-05,
      "loss": 0.2585,
      "step": 5700
    },
    {
      "epoch": 1.151441822948175,
      "grad_norm": 0.6773960590362549,
      "learning_rate": 2.1218995765275258e-05,
      "loss": 0.2946,
      "step": 5710
    },
    {
      "epoch": 1.1534583585400282,
      "grad_norm": 3.009194850921631,
      "learning_rate": 2.1168582375478928e-05,
      "loss": 0.3407,
      "step": 5720
    },
    {
      "epoch": 1.1554748941318813,
      "grad_norm": 5.907620906829834,
      "learning_rate": 2.1118168985682598e-05,
      "loss": 0.4656,
      "step": 5730
    },
    {
      "epoch": 1.1574914297237346,
      "grad_norm": 0.6544418931007385,
      "learning_rate": 2.1067755595886268e-05,
      "loss": 0.2826,
      "step": 5740
    },
    {
      "epoch": 1.1595079653155878,
      "grad_norm": 1.1188851594924927,
      "learning_rate": 2.1017342206089937e-05,
      "loss": 0.3468,
      "step": 5750
    },
    {
      "epoch": 1.161524500907441,
      "grad_norm": 19.80659294128418,
      "learning_rate": 2.0966928816293607e-05,
      "loss": 0.1779,
      "step": 5760
    },
    {
      "epoch": 1.1635410364992942,
      "grad_norm": 12.152664184570312,
      "learning_rate": 2.091651542649728e-05,
      "loss": 0.2887,
      "step": 5770
    },
    {
      "epoch": 1.1655575720911475,
      "grad_norm": 20.14624786376953,
      "learning_rate": 2.086610203670095e-05,
      "loss": 0.4686,
      "step": 5780
    },
    {
      "epoch": 1.1675741076830006,
      "grad_norm": 4.66944694519043,
      "learning_rate": 2.081568864690462e-05,
      "loss": 0.4857,
      "step": 5790
    },
    {
      "epoch": 1.1695906432748537,
      "grad_norm": 2.7775628566741943,
      "learning_rate": 2.0765275257108287e-05,
      "loss": 0.381,
      "step": 5800
    },
    {
      "epoch": 1.171607178866707,
      "grad_norm": 11.729440689086914,
      "learning_rate": 2.071486186731196e-05,
      "loss": 0.4159,
      "step": 5810
    },
    {
      "epoch": 1.1736237144585602,
      "grad_norm": 4.06296443939209,
      "learning_rate": 2.066444847751563e-05,
      "loss": 0.1662,
      "step": 5820
    },
    {
      "epoch": 1.1756402500504133,
      "grad_norm": 13.151472091674805,
      "learning_rate": 2.06140350877193e-05,
      "loss": 0.2061,
      "step": 5830
    },
    {
      "epoch": 1.1776567856422666,
      "grad_norm": 23.098424911499023,
      "learning_rate": 2.056362169792297e-05,
      "loss": 0.5269,
      "step": 5840
    },
    {
      "epoch": 1.1796733212341197,
      "grad_norm": 38.04499816894531,
      "learning_rate": 2.051320830812664e-05,
      "loss": 0.4883,
      "step": 5850
    },
    {
      "epoch": 1.181689856825973,
      "grad_norm": 52.92232894897461,
      "learning_rate": 2.046279491833031e-05,
      "loss": 0.4842,
      "step": 5860
    },
    {
      "epoch": 1.1837063924178262,
      "grad_norm": 42.72624969482422,
      "learning_rate": 2.041238152853398e-05,
      "loss": 0.5639,
      "step": 5870
    },
    {
      "epoch": 1.1857229280096795,
      "grad_norm": 19.54100227355957,
      "learning_rate": 2.036196813873765e-05,
      "loss": 0.4864,
      "step": 5880
    },
    {
      "epoch": 1.1877394636015326,
      "grad_norm": 0.6591483950614929,
      "learning_rate": 2.031155474894132e-05,
      "loss": 0.2889,
      "step": 5890
    },
    {
      "epoch": 1.1897559991933857,
      "grad_norm": 7.3004279136657715,
      "learning_rate": 2.026114135914499e-05,
      "loss": 0.4356,
      "step": 5900
    },
    {
      "epoch": 1.191772534785239,
      "grad_norm": 11.267752647399902,
      "learning_rate": 2.0210727969348662e-05,
      "loss": 0.5713,
      "step": 5910
    },
    {
      "epoch": 1.1937890703770921,
      "grad_norm": 5.84604549407959,
      "learning_rate": 2.0160314579552332e-05,
      "loss": 0.2782,
      "step": 5920
    },
    {
      "epoch": 1.1958056059689453,
      "grad_norm": 0.8781474828720093,
      "learning_rate": 2.0109901189756002e-05,
      "loss": 0.1925,
      "step": 5930
    },
    {
      "epoch": 1.1978221415607986,
      "grad_norm": 15.14405345916748,
      "learning_rate": 2.0059487799959668e-05,
      "loss": 0.2336,
      "step": 5940
    },
    {
      "epoch": 1.1998386771526517,
      "grad_norm": 25.464967727661133,
      "learning_rate": 2.0009074410163338e-05,
      "loss": 0.5903,
      "step": 5950
    },
    {
      "epoch": 1.201855212744505,
      "grad_norm": 13.515875816345215,
      "learning_rate": 1.995866102036701e-05,
      "loss": 0.2896,
      "step": 5960
    },
    {
      "epoch": 1.2038717483363581,
      "grad_norm": 25.257747650146484,
      "learning_rate": 1.990824763057068e-05,
      "loss": 0.2588,
      "step": 5970
    },
    {
      "epoch": 1.2058882839282115,
      "grad_norm": 2.966346502304077,
      "learning_rate": 1.985783424077435e-05,
      "loss": 0.3393,
      "step": 5980
    },
    {
      "epoch": 1.2079048195200646,
      "grad_norm": 2.098184108734131,
      "learning_rate": 1.980742085097802e-05,
      "loss": 0.2445,
      "step": 5990
    },
    {
      "epoch": 1.2099213551119177,
      "grad_norm": 0.587573230266571,
      "learning_rate": 1.975700746118169e-05,
      "loss": 0.2784,
      "step": 6000
    },
    {
      "epoch": 1.211937890703771,
      "grad_norm": 2.0063610076904297,
      "learning_rate": 1.970659407138536e-05,
      "loss": 0.3788,
      "step": 6010
    },
    {
      "epoch": 1.2139544262956241,
      "grad_norm": 8.539140701293945,
      "learning_rate": 1.965618068158903e-05,
      "loss": 0.2796,
      "step": 6020
    },
    {
      "epoch": 1.2159709618874772,
      "grad_norm": 1.2299915552139282,
      "learning_rate": 1.96057672917927e-05,
      "loss": 0.2453,
      "step": 6030
    },
    {
      "epoch": 1.2179874974793305,
      "grad_norm": 8.977559089660645,
      "learning_rate": 1.955535390199637e-05,
      "loss": 0.2827,
      "step": 6040
    },
    {
      "epoch": 1.2200040330711837,
      "grad_norm": 7.957054615020752,
      "learning_rate": 1.950494051220004e-05,
      "loss": 0.2306,
      "step": 6050
    },
    {
      "epoch": 1.222020568663037,
      "grad_norm": 1.6450937986373901,
      "learning_rate": 1.9454527122403713e-05,
      "loss": 0.2849,
      "step": 6060
    },
    {
      "epoch": 1.22403710425489,
      "grad_norm": 5.291160583496094,
      "learning_rate": 1.9404113732607383e-05,
      "loss": 0.347,
      "step": 6070
    },
    {
      "epoch": 1.2260536398467432,
      "grad_norm": 27.08119010925293,
      "learning_rate": 1.935370034281105e-05,
      "loss": 0.3234,
      "step": 6080
    },
    {
      "epoch": 1.2280701754385965,
      "grad_norm": 12.03989315032959,
      "learning_rate": 1.930328695301472e-05,
      "loss": 0.4072,
      "step": 6090
    },
    {
      "epoch": 1.2300867110304496,
      "grad_norm": 1.9357073307037354,
      "learning_rate": 1.925287356321839e-05,
      "loss": 0.1715,
      "step": 6100
    },
    {
      "epoch": 1.232103246622303,
      "grad_norm": 211.01119995117188,
      "learning_rate": 1.9202460173422063e-05,
      "loss": 0.279,
      "step": 6110
    },
    {
      "epoch": 1.234119782214156,
      "grad_norm": 0.5166075229644775,
      "learning_rate": 1.9152046783625733e-05,
      "loss": 0.2711,
      "step": 6120
    },
    {
      "epoch": 1.2361363178060092,
      "grad_norm": 4.417092800140381,
      "learning_rate": 1.9101633393829402e-05,
      "loss": 0.2778,
      "step": 6130
    },
    {
      "epoch": 1.2381528533978625,
      "grad_norm": 0.47387391328811646,
      "learning_rate": 1.9051220004033072e-05,
      "loss": 0.3101,
      "step": 6140
    },
    {
      "epoch": 1.2401693889897156,
      "grad_norm": 12.724716186523438,
      "learning_rate": 1.9000806614236742e-05,
      "loss": 0.2831,
      "step": 6150
    },
    {
      "epoch": 1.242185924581569,
      "grad_norm": 51.60658264160156,
      "learning_rate": 1.8950393224440412e-05,
      "loss": 0.2617,
      "step": 6160
    },
    {
      "epoch": 1.244202460173422,
      "grad_norm": 2.230555534362793,
      "learning_rate": 1.8899979834644082e-05,
      "loss": 0.6553,
      "step": 6170
    },
    {
      "epoch": 1.2462189957652752,
      "grad_norm": 0.9531410932540894,
      "learning_rate": 1.8849566444847752e-05,
      "loss": 0.2344,
      "step": 6180
    },
    {
      "epoch": 1.2482355313571285,
      "grad_norm": 13.851966857910156,
      "learning_rate": 1.879915305505142e-05,
      "loss": 0.3049,
      "step": 6190
    },
    {
      "epoch": 1.2502520669489816,
      "grad_norm": 11.000823974609375,
      "learning_rate": 1.8748739665255095e-05,
      "loss": 0.4533,
      "step": 6200
    },
    {
      "epoch": 1.252268602540835,
      "grad_norm": 0.8480364680290222,
      "learning_rate": 1.8698326275458765e-05,
      "loss": 0.4347,
      "step": 6210
    },
    {
      "epoch": 1.254285138132688,
      "grad_norm": 7.615712642669678,
      "learning_rate": 1.8647912885662435e-05,
      "loss": 0.4951,
      "step": 6220
    },
    {
      "epoch": 1.2563016737245412,
      "grad_norm": 1.2699021100997925,
      "learning_rate": 1.85974994958661e-05,
      "loss": 0.1858,
      "step": 6230
    },
    {
      "epoch": 1.2583182093163945,
      "grad_norm": 55.627227783203125,
      "learning_rate": 1.854708610606977e-05,
      "loss": 0.2674,
      "step": 6240
    },
    {
      "epoch": 1.2603347449082476,
      "grad_norm": 2.4707107543945312,
      "learning_rate": 1.8496672716273444e-05,
      "loss": 0.3036,
      "step": 6250
    },
    {
      "epoch": 1.2623512805001007,
      "grad_norm": 2.410623550415039,
      "learning_rate": 1.8446259326477114e-05,
      "loss": 0.1985,
      "step": 6260
    },
    {
      "epoch": 1.264367816091954,
      "grad_norm": 3.0108439922332764,
      "learning_rate": 1.8395845936680784e-05,
      "loss": 0.279,
      "step": 6270
    },
    {
      "epoch": 1.2663843516838071,
      "grad_norm": 5.21116828918457,
      "learning_rate": 1.8345432546884454e-05,
      "loss": 0.334,
      "step": 6280
    },
    {
      "epoch": 1.2684008872756605,
      "grad_norm": 0.6143179535865784,
      "learning_rate": 1.8295019157088124e-05,
      "loss": 0.182,
      "step": 6290
    },
    {
      "epoch": 1.2704174228675136,
      "grad_norm": 4.272446155548096,
      "learning_rate": 1.8244605767291794e-05,
      "loss": 0.3273,
      "step": 6300
    },
    {
      "epoch": 1.272433958459367,
      "grad_norm": 27.427581787109375,
      "learning_rate": 1.8194192377495463e-05,
      "loss": 0.605,
      "step": 6310
    },
    {
      "epoch": 1.27445049405122,
      "grad_norm": 0.44012224674224854,
      "learning_rate": 1.8143778987699133e-05,
      "loss": 0.1024,
      "step": 6320
    },
    {
      "epoch": 1.2764670296430731,
      "grad_norm": 14.368880271911621,
      "learning_rate": 1.8093365597902803e-05,
      "loss": 0.4018,
      "step": 6330
    },
    {
      "epoch": 1.2784835652349265,
      "grad_norm": 1.1122137308120728,
      "learning_rate": 1.8042952208106473e-05,
      "loss": 0.2102,
      "step": 6340
    },
    {
      "epoch": 1.2805001008267796,
      "grad_norm": 3.075962781906128,
      "learning_rate": 1.7992538818310146e-05,
      "loss": 0.2006,
      "step": 6350
    },
    {
      "epoch": 1.2825166364186327,
      "grad_norm": 3.8270516395568848,
      "learning_rate": 1.7942125428513816e-05,
      "loss": 0.2913,
      "step": 6360
    },
    {
      "epoch": 1.284533172010486,
      "grad_norm": 6.761003017425537,
      "learning_rate": 1.7891712038717483e-05,
      "loss": 0.352,
      "step": 6370
    },
    {
      "epoch": 1.286549707602339,
      "grad_norm": 2.175541400909424,
      "learning_rate": 1.7841298648921152e-05,
      "loss": 0.2048,
      "step": 6380
    },
    {
      "epoch": 1.2885662431941924,
      "grad_norm": 7.024525165557861,
      "learning_rate": 1.7790885259124822e-05,
      "loss": 0.5218,
      "step": 6390
    },
    {
      "epoch": 1.2905827787860455,
      "grad_norm": 9.134725570678711,
      "learning_rate": 1.7740471869328496e-05,
      "loss": 0.4039,
      "step": 6400
    },
    {
      "epoch": 1.2925993143778989,
      "grad_norm": 10.97361946105957,
      "learning_rate": 1.7690058479532165e-05,
      "loss": 0.2491,
      "step": 6410
    },
    {
      "epoch": 1.294615849969752,
      "grad_norm": 2.8118529319763184,
      "learning_rate": 1.7639645089735835e-05,
      "loss": 0.4797,
      "step": 6420
    },
    {
      "epoch": 1.296632385561605,
      "grad_norm": 1.3068115711212158,
      "learning_rate": 1.7589231699939505e-05,
      "loss": 0.2976,
      "step": 6430
    },
    {
      "epoch": 1.2986489211534584,
      "grad_norm": 14.442099571228027,
      "learning_rate": 1.7538818310143175e-05,
      "loss": 0.3405,
      "step": 6440
    },
    {
      "epoch": 1.3006654567453115,
      "grad_norm": 1.249511957168579,
      "learning_rate": 1.7488404920346845e-05,
      "loss": 0.2163,
      "step": 6450
    },
    {
      "epoch": 1.3026819923371646,
      "grad_norm": 7.514983177185059,
      "learning_rate": 1.7437991530550515e-05,
      "loss": 0.3049,
      "step": 6460
    },
    {
      "epoch": 1.304698527929018,
      "grad_norm": 7.657804012298584,
      "learning_rate": 1.7387578140754185e-05,
      "loss": 0.4692,
      "step": 6470
    },
    {
      "epoch": 1.306715063520871,
      "grad_norm": 6.644469738006592,
      "learning_rate": 1.7337164750957855e-05,
      "loss": 0.3103,
      "step": 6480
    },
    {
      "epoch": 1.3087315991127244,
      "grad_norm": 48.03805160522461,
      "learning_rate": 1.7286751361161528e-05,
      "loss": 0.2779,
      "step": 6490
    },
    {
      "epoch": 1.3107481347045775,
      "grad_norm": 24.51067543029785,
      "learning_rate": 1.7236337971365198e-05,
      "loss": 0.3501,
      "step": 6500
    },
    {
      "epoch": 1.3127646702964308,
      "grad_norm": 1.3524515628814697,
      "learning_rate": 1.7185924581568864e-05,
      "loss": 0.3168,
      "step": 6510
    },
    {
      "epoch": 1.314781205888284,
      "grad_norm": 6.782430648803711,
      "learning_rate": 1.7135511191772534e-05,
      "loss": 0.4321,
      "step": 6520
    },
    {
      "epoch": 1.316797741480137,
      "grad_norm": 18.947784423828125,
      "learning_rate": 1.7085097801976204e-05,
      "loss": 0.3239,
      "step": 6530
    },
    {
      "epoch": 1.3188142770719904,
      "grad_norm": 2.94653582572937,
      "learning_rate": 1.7034684412179877e-05,
      "loss": 0.1977,
      "step": 6540
    },
    {
      "epoch": 1.3208308126638435,
      "grad_norm": 4.608603000640869,
      "learning_rate": 1.6984271022383547e-05,
      "loss": 0.3952,
      "step": 6550
    },
    {
      "epoch": 1.3228473482556966,
      "grad_norm": 13.240279197692871,
      "learning_rate": 1.6933857632587217e-05,
      "loss": 0.3048,
      "step": 6560
    },
    {
      "epoch": 1.32486388384755,
      "grad_norm": 13.317240715026855,
      "learning_rate": 1.6883444242790887e-05,
      "loss": 0.2885,
      "step": 6570
    },
    {
      "epoch": 1.326880419439403,
      "grad_norm": 8.31171703338623,
      "learning_rate": 1.6833030852994557e-05,
      "loss": 0.3596,
      "step": 6580
    },
    {
      "epoch": 1.3288969550312564,
      "grad_norm": 22.989316940307617,
      "learning_rate": 1.6782617463198226e-05,
      "loss": 0.2585,
      "step": 6590
    },
    {
      "epoch": 1.3309134906231095,
      "grad_norm": 2.6082839965820312,
      "learning_rate": 1.6732204073401896e-05,
      "loss": 0.3882,
      "step": 6600
    },
    {
      "epoch": 1.3329300262149628,
      "grad_norm": 2.166630268096924,
      "learning_rate": 1.6681790683605566e-05,
      "loss": 0.3234,
      "step": 6610
    },
    {
      "epoch": 1.334946561806816,
      "grad_norm": 0.6271896958351135,
      "learning_rate": 1.6631377293809236e-05,
      "loss": 0.0861,
      "step": 6620
    },
    {
      "epoch": 1.336963097398669,
      "grad_norm": 0.8265002369880676,
      "learning_rate": 1.6580963904012906e-05,
      "loss": 0.3785,
      "step": 6630
    },
    {
      "epoch": 1.3389796329905224,
      "grad_norm": 14.733251571655273,
      "learning_rate": 1.653055051421658e-05,
      "loss": 0.3402,
      "step": 6640
    },
    {
      "epoch": 1.3409961685823755,
      "grad_norm": 106.62739562988281,
      "learning_rate": 1.648013712442025e-05,
      "loss": 0.3725,
      "step": 6650
    },
    {
      "epoch": 1.3430127041742286,
      "grad_norm": 3.3872292041778564,
      "learning_rate": 1.6429723734623915e-05,
      "loss": 0.4227,
      "step": 6660
    },
    {
      "epoch": 1.345029239766082,
      "grad_norm": 6.302279472351074,
      "learning_rate": 1.6379310344827585e-05,
      "loss": 0.2428,
      "step": 6670
    },
    {
      "epoch": 1.347045775357935,
      "grad_norm": 6.500408172607422,
      "learning_rate": 1.6328896955031255e-05,
      "loss": 0.279,
      "step": 6680
    },
    {
      "epoch": 1.3490623109497883,
      "grad_norm": 0.6600368618965149,
      "learning_rate": 1.627848356523493e-05,
      "loss": 0.3847,
      "step": 6690
    },
    {
      "epoch": 1.3510788465416415,
      "grad_norm": 1.1893726587295532,
      "learning_rate": 1.62280701754386e-05,
      "loss": 0.2681,
      "step": 6700
    },
    {
      "epoch": 1.3530953821334948,
      "grad_norm": 124.46528625488281,
      "learning_rate": 1.6177656785642268e-05,
      "loss": 0.2308,
      "step": 6710
    },
    {
      "epoch": 1.355111917725348,
      "grad_norm": 36.16244888305664,
      "learning_rate": 1.6127243395845938e-05,
      "loss": 0.3447,
      "step": 6720
    },
    {
      "epoch": 1.357128453317201,
      "grad_norm": 7.005136013031006,
      "learning_rate": 1.6076830006049608e-05,
      "loss": 0.516,
      "step": 6730
    },
    {
      "epoch": 1.3591449889090543,
      "grad_norm": 24.868175506591797,
      "learning_rate": 1.6026416616253278e-05,
      "loss": 0.3005,
      "step": 6740
    },
    {
      "epoch": 1.3611615245009074,
      "grad_norm": 1.2586853504180908,
      "learning_rate": 1.5976003226456948e-05,
      "loss": 0.5183,
      "step": 6750
    },
    {
      "epoch": 1.3631780600927605,
      "grad_norm": 1.2670832872390747,
      "learning_rate": 1.5925589836660618e-05,
      "loss": 0.2531,
      "step": 6760
    },
    {
      "epoch": 1.3651945956846139,
      "grad_norm": 0.5399641394615173,
      "learning_rate": 1.5875176446864287e-05,
      "loss": 0.2614,
      "step": 6770
    },
    {
      "epoch": 1.367211131276467,
      "grad_norm": 3.347557544708252,
      "learning_rate": 1.5824763057067957e-05,
      "loss": 0.2243,
      "step": 6780
    },
    {
      "epoch": 1.36922766686832,
      "grad_norm": 92.81730651855469,
      "learning_rate": 1.577434966727163e-05,
      "loss": 0.4778,
      "step": 6790
    },
    {
      "epoch": 1.3712442024601734,
      "grad_norm": 19.675350189208984,
      "learning_rate": 1.5723936277475297e-05,
      "loss": 0.5083,
      "step": 6800
    },
    {
      "epoch": 1.3732607380520268,
      "grad_norm": 1.707848072052002,
      "learning_rate": 1.5673522887678967e-05,
      "loss": 0.2181,
      "step": 6810
    },
    {
      "epoch": 1.3752772736438799,
      "grad_norm": 25.788368225097656,
      "learning_rate": 1.5623109497882637e-05,
      "loss": 0.3857,
      "step": 6820
    },
    {
      "epoch": 1.377293809235733,
      "grad_norm": 14.038516998291016,
      "learning_rate": 1.557269610808631e-05,
      "loss": 0.3711,
      "step": 6830
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 4.345668792724609,
      "learning_rate": 1.552228271828998e-05,
      "loss": 0.291,
      "step": 6840
    },
    {
      "epoch": 1.3813268804194394,
      "grad_norm": 2.122676134109497,
      "learning_rate": 1.547186932849365e-05,
      "loss": 0.3975,
      "step": 6850
    },
    {
      "epoch": 1.3833434160112925,
      "grad_norm": 20.602516174316406,
      "learning_rate": 1.542145593869732e-05,
      "loss": 0.3817,
      "step": 6860
    },
    {
      "epoch": 1.3853599516031458,
      "grad_norm": 58.5522575378418,
      "learning_rate": 1.537104254890099e-05,
      "loss": 0.3178,
      "step": 6870
    },
    {
      "epoch": 1.387376487194999,
      "grad_norm": 2.7215754985809326,
      "learning_rate": 1.532062915910466e-05,
      "loss": 0.3097,
      "step": 6880
    },
    {
      "epoch": 1.389393022786852,
      "grad_norm": 0.5876063704490662,
      "learning_rate": 1.527021576930833e-05,
      "loss": 0.2423,
      "step": 6890
    },
    {
      "epoch": 1.3914095583787054,
      "grad_norm": 3.4013993740081787,
      "learning_rate": 1.5219802379511999e-05,
      "loss": 0.1879,
      "step": 6900
    },
    {
      "epoch": 1.3934260939705585,
      "grad_norm": 0.4767087996006012,
      "learning_rate": 1.5169388989715669e-05,
      "loss": 0.3557,
      "step": 6910
    },
    {
      "epoch": 1.3954426295624118,
      "grad_norm": 8.03844928741455,
      "learning_rate": 1.5118975599919339e-05,
      "loss": 0.5743,
      "step": 6920
    },
    {
      "epoch": 1.397459165154265,
      "grad_norm": 4.137035369873047,
      "learning_rate": 1.506856221012301e-05,
      "loss": 0.352,
      "step": 6930
    },
    {
      "epoch": 1.3994757007461183,
      "grad_norm": 2.1531543731689453,
      "learning_rate": 1.501814882032668e-05,
      "loss": 0.2385,
      "step": 6940
    },
    {
      "epoch": 1.4014922363379714,
      "grad_norm": 24.747480392456055,
      "learning_rate": 1.496773543053035e-05,
      "loss": 0.2704,
      "step": 6950
    },
    {
      "epoch": 1.4035087719298245,
      "grad_norm": 17.251108169555664,
      "learning_rate": 1.491732204073402e-05,
      "loss": 0.3327,
      "step": 6960
    },
    {
      "epoch": 1.4055253075216778,
      "grad_norm": 0.6776443719863892,
      "learning_rate": 1.4866908650937688e-05,
      "loss": 0.2848,
      "step": 6970
    },
    {
      "epoch": 1.407541843113531,
      "grad_norm": 1.33744215965271,
      "learning_rate": 1.4816495261141361e-05,
      "loss": 0.4221,
      "step": 6980
    },
    {
      "epoch": 1.409558378705384,
      "grad_norm": 2.1144583225250244,
      "learning_rate": 1.4766081871345031e-05,
      "loss": 0.2449,
      "step": 6990
    },
    {
      "epoch": 1.4115749142972374,
      "grad_norm": 0.7211073637008667,
      "learning_rate": 1.47156684815487e-05,
      "loss": 0.2046,
      "step": 7000
    },
    {
      "epoch": 1.4135914498890905,
      "grad_norm": 75.20755004882812,
      "learning_rate": 1.466525509175237e-05,
      "loss": 0.3985,
      "step": 7010
    },
    {
      "epoch": 1.4156079854809438,
      "grad_norm": 0.6272091269493103,
      "learning_rate": 1.4614841701956039e-05,
      "loss": 0.3227,
      "step": 7020
    },
    {
      "epoch": 1.417624521072797,
      "grad_norm": 0.689103901386261,
      "learning_rate": 1.456442831215971e-05,
      "loss": 0.2999,
      "step": 7030
    },
    {
      "epoch": 1.4196410566646502,
      "grad_norm": 5.0292558670043945,
      "learning_rate": 1.451401492236338e-05,
      "loss": 0.3122,
      "step": 7040
    },
    {
      "epoch": 1.4216575922565033,
      "grad_norm": 51.594730377197266,
      "learning_rate": 1.446360153256705e-05,
      "loss": 0.3894,
      "step": 7050
    },
    {
      "epoch": 1.4236741278483565,
      "grad_norm": 20.325803756713867,
      "learning_rate": 1.441318814277072e-05,
      "loss": 0.2446,
      "step": 7060
    },
    {
      "epoch": 1.4256906634402098,
      "grad_norm": 3.2688839435577393,
      "learning_rate": 1.436277475297439e-05,
      "loss": 0.2581,
      "step": 7070
    },
    {
      "epoch": 1.427707199032063,
      "grad_norm": 13.434335708618164,
      "learning_rate": 1.4312361363178062e-05,
      "loss": 0.4669,
      "step": 7080
    },
    {
      "epoch": 1.429723734623916,
      "grad_norm": 22.419878005981445,
      "learning_rate": 1.4261947973381732e-05,
      "loss": 0.3513,
      "step": 7090
    },
    {
      "epoch": 1.4317402702157693,
      "grad_norm": 6.186263561248779,
      "learning_rate": 1.4211534583585401e-05,
      "loss": 0.2657,
      "step": 7100
    },
    {
      "epoch": 1.4337568058076224,
      "grad_norm": 5.673337459564209,
      "learning_rate": 1.416112119378907e-05,
      "loss": 0.2428,
      "step": 7110
    },
    {
      "epoch": 1.4357733413994758,
      "grad_norm": 5.221510887145996,
      "learning_rate": 1.411070780399274e-05,
      "loss": 0.335,
      "step": 7120
    },
    {
      "epoch": 1.4377898769913289,
      "grad_norm": 7.005497455596924,
      "learning_rate": 1.4060294414196413e-05,
      "loss": 0.2468,
      "step": 7130
    },
    {
      "epoch": 1.4398064125831822,
      "grad_norm": 2.8823962211608887,
      "learning_rate": 1.4009881024400081e-05,
      "loss": 0.6106,
      "step": 7140
    },
    {
      "epoch": 1.4418229481750353,
      "grad_norm": 0.4090741276741028,
      "learning_rate": 1.395946763460375e-05,
      "loss": 0.1859,
      "step": 7150
    },
    {
      "epoch": 1.4438394837668884,
      "grad_norm": 21.540393829345703,
      "learning_rate": 1.390905424480742e-05,
      "loss": 0.2769,
      "step": 7160
    },
    {
      "epoch": 1.4458560193587418,
      "grad_norm": 4.024837970733643,
      "learning_rate": 1.3858640855011092e-05,
      "loss": 0.369,
      "step": 7170
    },
    {
      "epoch": 1.4478725549505949,
      "grad_norm": 5.352239608764648,
      "learning_rate": 1.3808227465214762e-05,
      "loss": 0.2973,
      "step": 7180
    },
    {
      "epoch": 1.449889090542448,
      "grad_norm": 0.6707779169082642,
      "learning_rate": 1.3757814075418432e-05,
      "loss": 0.2154,
      "step": 7190
    },
    {
      "epoch": 1.4519056261343013,
      "grad_norm": 0.6220439076423645,
      "learning_rate": 1.3707400685622102e-05,
      "loss": 0.2565,
      "step": 7200
    },
    {
      "epoch": 1.4539221617261544,
      "grad_norm": 21.319137573242188,
      "learning_rate": 1.3656987295825772e-05,
      "loss": 0.3351,
      "step": 7210
    },
    {
      "epoch": 1.4559386973180077,
      "grad_norm": 19.998275756835938,
      "learning_rate": 1.3606573906029443e-05,
      "loss": 0.2203,
      "step": 7220
    },
    {
      "epoch": 1.4579552329098608,
      "grad_norm": 2.984586477279663,
      "learning_rate": 1.3556160516233113e-05,
      "loss": 0.3127,
      "step": 7230
    },
    {
      "epoch": 1.4599717685017142,
      "grad_norm": 2.8393657207489014,
      "learning_rate": 1.3505747126436783e-05,
      "loss": 0.5059,
      "step": 7240
    },
    {
      "epoch": 1.4619883040935673,
      "grad_norm": 16.317907333374023,
      "learning_rate": 1.3455333736640453e-05,
      "loss": 0.2839,
      "step": 7250
    },
    {
      "epoch": 1.4640048396854204,
      "grad_norm": 23.5967960357666,
      "learning_rate": 1.3404920346844121e-05,
      "loss": 0.1922,
      "step": 7260
    },
    {
      "epoch": 1.4660213752772737,
      "grad_norm": 8.098050117492676,
      "learning_rate": 1.3354506957047794e-05,
      "loss": 0.4211,
      "step": 7270
    },
    {
      "epoch": 1.4680379108691268,
      "grad_norm": 48.19622802734375,
      "learning_rate": 1.3304093567251464e-05,
      "loss": 0.5029,
      "step": 7280
    },
    {
      "epoch": 1.47005444646098,
      "grad_norm": 1.0303694009780884,
      "learning_rate": 1.3253680177455132e-05,
      "loss": 0.1437,
      "step": 7290
    },
    {
      "epoch": 1.4720709820528333,
      "grad_norm": 0.32965537905693054,
      "learning_rate": 1.3203266787658802e-05,
      "loss": 0.3085,
      "step": 7300
    },
    {
      "epoch": 1.4740875176446864,
      "grad_norm": 16.496150970458984,
      "learning_rate": 1.3152853397862472e-05,
      "loss": 0.3423,
      "step": 7310
    },
    {
      "epoch": 1.4761040532365397,
      "grad_norm": 15.287528991699219,
      "learning_rate": 1.3102440008066144e-05,
      "loss": 0.359,
      "step": 7320
    },
    {
      "epoch": 1.4781205888283928,
      "grad_norm": 11.182291030883789,
      "learning_rate": 1.3052026618269813e-05,
      "loss": 0.1784,
      "step": 7330
    },
    {
      "epoch": 1.4801371244202461,
      "grad_norm": 20.821720123291016,
      "learning_rate": 1.3001613228473483e-05,
      "loss": 0.6972,
      "step": 7340
    },
    {
      "epoch": 1.4821536600120992,
      "grad_norm": 0.9478353261947632,
      "learning_rate": 1.2951199838677153e-05,
      "loss": 0.3697,
      "step": 7350
    },
    {
      "epoch": 1.4841701956039524,
      "grad_norm": 0.4729630649089813,
      "learning_rate": 1.2900786448880823e-05,
      "loss": 0.4101,
      "step": 7360
    },
    {
      "epoch": 1.4861867311958057,
      "grad_norm": 140.7045135498047,
      "learning_rate": 1.2850373059084495e-05,
      "loss": 0.3485,
      "step": 7370
    },
    {
      "epoch": 1.4882032667876588,
      "grad_norm": 1.9115601778030396,
      "learning_rate": 1.2799959669288164e-05,
      "loss": 0.3741,
      "step": 7380
    },
    {
      "epoch": 1.490219802379512,
      "grad_norm": 7.518259525299072,
      "learning_rate": 1.2749546279491834e-05,
      "loss": 0.3055,
      "step": 7390
    },
    {
      "epoch": 1.4922363379713652,
      "grad_norm": 19.026519775390625,
      "learning_rate": 1.2699132889695502e-05,
      "loss": 0.3316,
      "step": 7400
    },
    {
      "epoch": 1.4942528735632183,
      "grad_norm": 2.843773365020752,
      "learning_rate": 1.2648719499899172e-05,
      "loss": 0.2979,
      "step": 7410
    },
    {
      "epoch": 1.4962694091550715,
      "grad_norm": 11.125473976135254,
      "learning_rate": 1.2598306110102846e-05,
      "loss": 0.3203,
      "step": 7420
    },
    {
      "epoch": 1.4982859447469248,
      "grad_norm": 0.6221499443054199,
      "learning_rate": 1.2547892720306514e-05,
      "loss": 0.2845,
      "step": 7430
    },
    {
      "epoch": 1.500302480338778,
      "grad_norm": 10.047194480895996,
      "learning_rate": 1.2497479330510184e-05,
      "loss": 0.3823,
      "step": 7440
    },
    {
      "epoch": 1.5023190159306312,
      "grad_norm": 0.42723649740219116,
      "learning_rate": 1.2447065940713855e-05,
      "loss": 0.1975,
      "step": 7450
    },
    {
      "epoch": 1.5043355515224843,
      "grad_norm": 14.149922370910645,
      "learning_rate": 1.2396652550917525e-05,
      "loss": 0.4217,
      "step": 7460
    },
    {
      "epoch": 1.5063520871143377,
      "grad_norm": 11.446324348449707,
      "learning_rate": 1.2346239161121193e-05,
      "loss": 0.4206,
      "step": 7470
    },
    {
      "epoch": 1.5083686227061908,
      "grad_norm": 45.87311553955078,
      "learning_rate": 1.2295825771324865e-05,
      "loss": 0.2463,
      "step": 7480
    },
    {
      "epoch": 1.5103851582980439,
      "grad_norm": 10.603595733642578,
      "learning_rate": 1.2245412381528535e-05,
      "loss": 0.3761,
      "step": 7490
    },
    {
      "epoch": 1.5124016938898972,
      "grad_norm": 3.1243221759796143,
      "learning_rate": 1.2194998991732204e-05,
      "loss": 0.2359,
      "step": 7500
    },
    {
      "epoch": 1.5144182294817503,
      "grad_norm": 0.5296769738197327,
      "learning_rate": 1.2144585601935874e-05,
      "loss": 0.2922,
      "step": 7510
    },
    {
      "epoch": 1.5164347650736034,
      "grad_norm": 7.866077899932861,
      "learning_rate": 1.2094172212139544e-05,
      "loss": 0.2447,
      "step": 7520
    },
    {
      "epoch": 1.5184513006654567,
      "grad_norm": 32.30732727050781,
      "learning_rate": 1.2043758822343216e-05,
      "loss": 0.2961,
      "step": 7530
    },
    {
      "epoch": 1.52046783625731,
      "grad_norm": 8.910194396972656,
      "learning_rate": 1.1993345432546884e-05,
      "loss": 0.2548,
      "step": 7540
    },
    {
      "epoch": 1.5224843718491632,
      "grad_norm": 0.9496402740478516,
      "learning_rate": 1.1942932042750555e-05,
      "loss": 0.2949,
      "step": 7550
    },
    {
      "epoch": 1.5245009074410163,
      "grad_norm": 4.8025383949279785,
      "learning_rate": 1.1892518652954225e-05,
      "loss": 0.4017,
      "step": 7560
    },
    {
      "epoch": 1.5265174430328696,
      "grad_norm": 0.510382354259491,
      "learning_rate": 1.1842105263157895e-05,
      "loss": 0.3307,
      "step": 7570
    },
    {
      "epoch": 1.5285339786247227,
      "grad_norm": 0.616015613079071,
      "learning_rate": 1.1791691873361565e-05,
      "loss": 0.1292,
      "step": 7580
    },
    {
      "epoch": 1.5305505142165758,
      "grad_norm": 9.210956573486328,
      "learning_rate": 1.1741278483565235e-05,
      "loss": 0.4765,
      "step": 7590
    },
    {
      "epoch": 1.5325670498084292,
      "grad_norm": 2.7557458877563477,
      "learning_rate": 1.1690865093768907e-05,
      "loss": 0.2499,
      "step": 7600
    },
    {
      "epoch": 1.5345835854002823,
      "grad_norm": 0.5947180390357971,
      "learning_rate": 1.1640451703972575e-05,
      "loss": 0.2783,
      "step": 7610
    },
    {
      "epoch": 1.5366001209921354,
      "grad_norm": 7.188604354858398,
      "learning_rate": 1.1590038314176246e-05,
      "loss": 0.3097,
      "step": 7620
    },
    {
      "epoch": 1.5386166565839887,
      "grad_norm": 0.5743528008460999,
      "learning_rate": 1.1539624924379916e-05,
      "loss": 0.2701,
      "step": 7630
    },
    {
      "epoch": 1.540633192175842,
      "grad_norm": 20.91383934020996,
      "learning_rate": 1.1489211534583586e-05,
      "loss": 0.4887,
      "step": 7640
    },
    {
      "epoch": 1.542649727767695,
      "grad_norm": 2.9780309200286865,
      "learning_rate": 1.1438798144787256e-05,
      "loss": 0.2269,
      "step": 7650
    },
    {
      "epoch": 1.5446662633595483,
      "grad_norm": 0.49887293577194214,
      "learning_rate": 1.1388384754990926e-05,
      "loss": 0.2864,
      "step": 7660
    },
    {
      "epoch": 1.5466827989514016,
      "grad_norm": 3.5030810832977295,
      "learning_rate": 1.1337971365194597e-05,
      "loss": 0.3053,
      "step": 7670
    },
    {
      "epoch": 1.5486993345432547,
      "grad_norm": 1.2655649185180664,
      "learning_rate": 1.1287557975398267e-05,
      "loss": 0.3904,
      "step": 7680
    },
    {
      "epoch": 1.5507158701351078,
      "grad_norm": 3.1367673873901367,
      "learning_rate": 1.1237144585601935e-05,
      "loss": 0.4913,
      "step": 7690
    },
    {
      "epoch": 1.5527324057269611,
      "grad_norm": 1.7007091045379639,
      "learning_rate": 1.1186731195805607e-05,
      "loss": 0.2161,
      "step": 7700
    },
    {
      "epoch": 1.5547489413188142,
      "grad_norm": 23.39369773864746,
      "learning_rate": 1.1136317806009277e-05,
      "loss": 0.3676,
      "step": 7710
    },
    {
      "epoch": 1.5567654769106674,
      "grad_norm": 64.254638671875,
      "learning_rate": 1.1085904416212947e-05,
      "loss": 0.3414,
      "step": 7720
    },
    {
      "epoch": 1.5587820125025207,
      "grad_norm": 39.5642204284668,
      "learning_rate": 1.1035491026416616e-05,
      "loss": 0.394,
      "step": 7730
    },
    {
      "epoch": 1.560798548094374,
      "grad_norm": 15.368971824645996,
      "learning_rate": 1.0985077636620286e-05,
      "loss": 0.4081,
      "step": 7740
    },
    {
      "epoch": 1.562815083686227,
      "grad_norm": 9.089579582214355,
      "learning_rate": 1.0934664246823958e-05,
      "loss": 0.154,
      "step": 7750
    },
    {
      "epoch": 1.5648316192780802,
      "grad_norm": 0.881633996963501,
      "learning_rate": 1.0884250857027626e-05,
      "loss": 0.2233,
      "step": 7760
    },
    {
      "epoch": 1.5668481548699336,
      "grad_norm": 21.10283851623535,
      "learning_rate": 1.0833837467231298e-05,
      "loss": 0.4113,
      "step": 7770
    },
    {
      "epoch": 1.5688646904617867,
      "grad_norm": 2.2369329929351807,
      "learning_rate": 1.0783424077434967e-05,
      "loss": 0.444,
      "step": 7780
    },
    {
      "epoch": 1.5708812260536398,
      "grad_norm": 4.954090118408203,
      "learning_rate": 1.0733010687638637e-05,
      "loss": 0.3382,
      "step": 7790
    },
    {
      "epoch": 1.572897761645493,
      "grad_norm": 2.654676675796509,
      "learning_rate": 1.0682597297842307e-05,
      "loss": 0.2904,
      "step": 7800
    },
    {
      "epoch": 1.5749142972373462,
      "grad_norm": 24.80543327331543,
      "learning_rate": 1.0632183908045977e-05,
      "loss": 0.3059,
      "step": 7810
    },
    {
      "epoch": 1.5769308328291993,
      "grad_norm": 0.41260793805122375,
      "learning_rate": 1.0581770518249649e-05,
      "loss": 0.2174,
      "step": 7820
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 15.70760440826416,
      "learning_rate": 1.0531357128453317e-05,
      "loss": 0.4969,
      "step": 7830
    },
    {
      "epoch": 1.580963904012906,
      "grad_norm": 7.454799175262451,
      "learning_rate": 1.0480943738656988e-05,
      "loss": 0.3481,
      "step": 7840
    },
    {
      "epoch": 1.5829804396047589,
      "grad_norm": 6.50785493850708,
      "learning_rate": 1.0430530348860658e-05,
      "loss": 0.3581,
      "step": 7850
    },
    {
      "epoch": 1.5849969751966122,
      "grad_norm": 2.5262210369110107,
      "learning_rate": 1.0380116959064328e-05,
      "loss": 0.3876,
      "step": 7860
    },
    {
      "epoch": 1.5870135107884655,
      "grad_norm": 6.350083827972412,
      "learning_rate": 1.0329703569267998e-05,
      "loss": 0.2916,
      "step": 7870
    },
    {
      "epoch": 1.5890300463803186,
      "grad_norm": 13.128668785095215,
      "learning_rate": 1.0279290179471668e-05,
      "loss": 0.1729,
      "step": 7880
    },
    {
      "epoch": 1.5910465819721717,
      "grad_norm": 2.3638970851898193,
      "learning_rate": 1.022887678967534e-05,
      "loss": 0.2971,
      "step": 7890
    },
    {
      "epoch": 1.593063117564025,
      "grad_norm": 1.6760363578796387,
      "learning_rate": 1.0178463399879008e-05,
      "loss": 0.3497,
      "step": 7900
    },
    {
      "epoch": 1.5950796531558782,
      "grad_norm": 10.841476440429688,
      "learning_rate": 1.0128050010082677e-05,
      "loss": 0.2168,
      "step": 7910
    },
    {
      "epoch": 1.5970961887477313,
      "grad_norm": 0.7075563073158264,
      "learning_rate": 1.0077636620286349e-05,
      "loss": 0.2831,
      "step": 7920
    },
    {
      "epoch": 1.5991127243395846,
      "grad_norm": 3.364002227783203,
      "learning_rate": 1.0027223230490019e-05,
      "loss": 0.4605,
      "step": 7930
    },
    {
      "epoch": 1.601129259931438,
      "grad_norm": 0.5822557210922241,
      "learning_rate": 9.976809840693689e-06,
      "loss": 0.2067,
      "step": 7940
    },
    {
      "epoch": 1.6031457955232908,
      "grad_norm": 0.5127565264701843,
      "learning_rate": 9.926396450897359e-06,
      "loss": 0.3001,
      "step": 7950
    },
    {
      "epoch": 1.6051623311151442,
      "grad_norm": 1.4032613039016724,
      "learning_rate": 9.87598306110103e-06,
      "loss": 0.19,
      "step": 7960
    },
    {
      "epoch": 1.6071788667069975,
      "grad_norm": 3.613565444946289,
      "learning_rate": 9.825569671304698e-06,
      "loss": 0.3225,
      "step": 7970
    },
    {
      "epoch": 1.6091954022988506,
      "grad_norm": 0.5828942060470581,
      "learning_rate": 9.775156281508368e-06,
      "loss": 0.2088,
      "step": 7980
    },
    {
      "epoch": 1.6112119378907037,
      "grad_norm": 0.7137711048126221,
      "learning_rate": 9.72474289171204e-06,
      "loss": 0.4499,
      "step": 7990
    },
    {
      "epoch": 1.613228473482557,
      "grad_norm": 3.425593852996826,
      "learning_rate": 9.67432950191571e-06,
      "loss": 0.2543,
      "step": 8000
    },
    {
      "epoch": 1.6152450090744102,
      "grad_norm": 4.484379768371582,
      "learning_rate": 9.62391611211938e-06,
      "loss": 0.4047,
      "step": 8010
    },
    {
      "epoch": 1.6172615446662633,
      "grad_norm": 17.077226638793945,
      "learning_rate": 9.57350272232305e-06,
      "loss": 0.2498,
      "step": 8020
    },
    {
      "epoch": 1.6192780802581166,
      "grad_norm": 0.3199479281902313,
      "learning_rate": 9.52308933252672e-06,
      "loss": 0.4033,
      "step": 8030
    },
    {
      "epoch": 1.6212946158499697,
      "grad_norm": 13.802295684814453,
      "learning_rate": 9.47267594273039e-06,
      "loss": 0.2614,
      "step": 8040
    },
    {
      "epoch": 1.6233111514418228,
      "grad_norm": 2.762768030166626,
      "learning_rate": 9.422262552934059e-06,
      "loss": 0.2283,
      "step": 8050
    },
    {
      "epoch": 1.6253276870336761,
      "grad_norm": 17.93149757385254,
      "learning_rate": 9.37184916313773e-06,
      "loss": 0.2193,
      "step": 8060
    },
    {
      "epoch": 1.6273442226255295,
      "grad_norm": 25.533466339111328,
      "learning_rate": 9.3214357733414e-06,
      "loss": 0.3505,
      "step": 8070
    },
    {
      "epoch": 1.6293607582173826,
      "grad_norm": 44.65237045288086,
      "learning_rate": 9.27102238354507e-06,
      "loss": 0.3273,
      "step": 8080
    },
    {
      "epoch": 1.6313772938092357,
      "grad_norm": 18.786937713623047,
      "learning_rate": 9.22060899374874e-06,
      "loss": 0.4177,
      "step": 8090
    },
    {
      "epoch": 1.633393829401089,
      "grad_norm": 8.17818832397461,
      "learning_rate": 9.17019560395241e-06,
      "loss": 0.1749,
      "step": 8100
    },
    {
      "epoch": 1.6354103649929421,
      "grad_norm": 13.101069450378418,
      "learning_rate": 9.119782214156081e-06,
      "loss": 0.2806,
      "step": 8110
    },
    {
      "epoch": 1.6374269005847952,
      "grad_norm": 0.4106931984424591,
      "learning_rate": 9.06936882435975e-06,
      "loss": 0.3529,
      "step": 8120
    },
    {
      "epoch": 1.6394434361766486,
      "grad_norm": 13.468987464904785,
      "learning_rate": 9.018955434563421e-06,
      "loss": 0.2113,
      "step": 8130
    },
    {
      "epoch": 1.6414599717685017,
      "grad_norm": 3.6040518283843994,
      "learning_rate": 8.968542044767091e-06,
      "loss": 0.2029,
      "step": 8140
    },
    {
      "epoch": 1.6434765073603548,
      "grad_norm": 1.735905408859253,
      "learning_rate": 8.918128654970761e-06,
      "loss": 0.3192,
      "step": 8150
    },
    {
      "epoch": 1.645493042952208,
      "grad_norm": 69.69204711914062,
      "learning_rate": 8.86771526517443e-06,
      "loss": 0.3968,
      "step": 8160
    },
    {
      "epoch": 1.6475095785440614,
      "grad_norm": 0.9023257493972778,
      "learning_rate": 8.8173018753781e-06,
      "loss": 0.3593,
      "step": 8170
    },
    {
      "epoch": 1.6495261141359145,
      "grad_norm": 22.675567626953125,
      "learning_rate": 8.766888485581772e-06,
      "loss": 0.3137,
      "step": 8180
    },
    {
      "epoch": 1.6515426497277677,
      "grad_norm": 2.5483248233795166,
      "learning_rate": 8.71647509578544e-06,
      "loss": 0.2885,
      "step": 8190
    },
    {
      "epoch": 1.653559185319621,
      "grad_norm": 6.943558692932129,
      "learning_rate": 8.66606170598911e-06,
      "loss": 0.1758,
      "step": 8200
    },
    {
      "epoch": 1.655575720911474,
      "grad_norm": 20.63728141784668,
      "learning_rate": 8.615648316192782e-06,
      "loss": 0.3293,
      "step": 8210
    },
    {
      "epoch": 1.6575922565033272,
      "grad_norm": 43.461883544921875,
      "learning_rate": 8.565234926396452e-06,
      "loss": 0.373,
      "step": 8220
    },
    {
      "epoch": 1.6596087920951805,
      "grad_norm": 7.318387985229492,
      "learning_rate": 8.514821536600122e-06,
      "loss": 0.1795,
      "step": 8230
    },
    {
      "epoch": 1.6616253276870336,
      "grad_norm": 20.718624114990234,
      "learning_rate": 8.464408146803791e-06,
      "loss": 0.2769,
      "step": 8240
    },
    {
      "epoch": 1.6636418632788867,
      "grad_norm": 10.957545280456543,
      "learning_rate": 8.413994757007461e-06,
      "loss": 0.1981,
      "step": 8250
    },
    {
      "epoch": 1.66565839887074,
      "grad_norm": 18.813884735107422,
      "learning_rate": 8.363581367211131e-06,
      "loss": 0.2471,
      "step": 8260
    },
    {
      "epoch": 1.6676749344625934,
      "grad_norm": 8.036798477172852,
      "learning_rate": 8.313167977414801e-06,
      "loss": 0.3726,
      "step": 8270
    },
    {
      "epoch": 1.6696914700544465,
      "grad_norm": 12.354199409484863,
      "learning_rate": 8.262754587618473e-06,
      "loss": 0.2223,
      "step": 8280
    },
    {
      "epoch": 1.6717080056462996,
      "grad_norm": 0.3545999228954315,
      "learning_rate": 8.212341197822142e-06,
      "loss": 0.4104,
      "step": 8290
    },
    {
      "epoch": 1.673724541238153,
      "grad_norm": 0.7419455051422119,
      "learning_rate": 8.161927808025812e-06,
      "loss": 0.3397,
      "step": 8300
    },
    {
      "epoch": 1.675741076830006,
      "grad_norm": 29.288515090942383,
      "learning_rate": 8.111514418229482e-06,
      "loss": 0.2128,
      "step": 8310
    },
    {
      "epoch": 1.6777576124218592,
      "grad_norm": 0.1493891477584839,
      "learning_rate": 8.061101028433152e-06,
      "loss": 0.3356,
      "step": 8320
    },
    {
      "epoch": 1.6797741480137125,
      "grad_norm": 77.18576049804688,
      "learning_rate": 8.010687638636822e-06,
      "loss": 0.1838,
      "step": 8330
    },
    {
      "epoch": 1.6817906836055656,
      "grad_norm": 8.675261497497559,
      "learning_rate": 7.960274248840492e-06,
      "loss": 0.3909,
      "step": 8340
    },
    {
      "epoch": 1.6838072191974187,
      "grad_norm": 27.964780807495117,
      "learning_rate": 7.909860859044163e-06,
      "loss": 0.2337,
      "step": 8350
    },
    {
      "epoch": 1.685823754789272,
      "grad_norm": 11.105741500854492,
      "learning_rate": 7.859447469247833e-06,
      "loss": 0.4249,
      "step": 8360
    },
    {
      "epoch": 1.6878402903811254,
      "grad_norm": 1.2660598754882812,
      "learning_rate": 7.809034079451501e-06,
      "loss": 0.3165,
      "step": 8370
    },
    {
      "epoch": 1.6898568259729783,
      "grad_norm": 5.780888080596924,
      "learning_rate": 7.758620689655173e-06,
      "loss": 0.4625,
      "step": 8380
    },
    {
      "epoch": 1.6918733615648316,
      "grad_norm": 3.9756267070770264,
      "learning_rate": 7.708207299858843e-06,
      "loss": 0.3396,
      "step": 8390
    },
    {
      "epoch": 1.693889897156685,
      "grad_norm": 9.696507453918457,
      "learning_rate": 7.657793910062513e-06,
      "loss": 0.1969,
      "step": 8400
    },
    {
      "epoch": 1.695906432748538,
      "grad_norm": 13.304756164550781,
      "learning_rate": 7.607380520266183e-06,
      "loss": 0.1277,
      "step": 8410
    },
    {
      "epoch": 1.6979229683403911,
      "grad_norm": 0.7777855396270752,
      "learning_rate": 7.556967130469852e-06,
      "loss": 0.4125,
      "step": 8420
    },
    {
      "epoch": 1.6999395039322445,
      "grad_norm": 3.8237931728363037,
      "learning_rate": 7.506553740673523e-06,
      "loss": 0.2813,
      "step": 8430
    },
    {
      "epoch": 1.7019560395240976,
      "grad_norm": 22.142398834228516,
      "learning_rate": 7.456140350877193e-06,
      "loss": 0.408,
      "step": 8440
    },
    {
      "epoch": 1.7039725751159507,
      "grad_norm": 8.575241088867188,
      "learning_rate": 7.405726961080864e-06,
      "loss": 0.4061,
      "step": 8450
    },
    {
      "epoch": 1.705989110707804,
      "grad_norm": 4.000797748565674,
      "learning_rate": 7.3553135712845335e-06,
      "loss": 0.2838,
      "step": 8460
    },
    {
      "epoch": 1.7080056462996573,
      "grad_norm": 27.30074691772461,
      "learning_rate": 7.304900181488204e-06,
      "loss": 0.312,
      "step": 8470
    },
    {
      "epoch": 1.7100221818915102,
      "grad_norm": 6.809289932250977,
      "learning_rate": 7.254486791691874e-06,
      "loss": 0.1722,
      "step": 8480
    },
    {
      "epoch": 1.7120387174833636,
      "grad_norm": 0.7904027104377747,
      "learning_rate": 7.204073401895543e-06,
      "loss": 0.238,
      "step": 8490
    },
    {
      "epoch": 1.714055253075217,
      "grad_norm": 43.77438735961914,
      "learning_rate": 7.153660012099214e-06,
      "loss": 0.2807,
      "step": 8500
    },
    {
      "epoch": 1.71607178866707,
      "grad_norm": 0.8023062944412231,
      "learning_rate": 7.103246622302884e-06,
      "loss": 0.1806,
      "step": 8510
    },
    {
      "epoch": 1.718088324258923,
      "grad_norm": 0.20670148730278015,
      "learning_rate": 7.052833232506554e-06,
      "loss": 0.3834,
      "step": 8520
    },
    {
      "epoch": 1.7201048598507764,
      "grad_norm": 8.515130996704102,
      "learning_rate": 7.002419842710224e-06,
      "loss": 0.3053,
      "step": 8530
    },
    {
      "epoch": 1.7221213954426295,
      "grad_norm": 0.7548246383666992,
      "learning_rate": 6.952006452913893e-06,
      "loss": 0.1319,
      "step": 8540
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 5.1090898513793945,
      "learning_rate": 6.901593063117565e-06,
      "loss": 0.1979,
      "step": 8550
    },
    {
      "epoch": 1.726154466626336,
      "grad_norm": 18.568256378173828,
      "learning_rate": 6.851179673321234e-06,
      "loss": 0.4723,
      "step": 8560
    },
    {
      "epoch": 1.7281710022181893,
      "grad_norm": 90.68351745605469,
      "learning_rate": 6.800766283524905e-06,
      "loss": 0.3468,
      "step": 8570
    },
    {
      "epoch": 1.7301875378100422,
      "grad_norm": 3.28733229637146,
      "learning_rate": 6.7503528937285744e-06,
      "loss": 0.3279,
      "step": 8580
    },
    {
      "epoch": 1.7322040734018955,
      "grad_norm": 1.420729637145996,
      "learning_rate": 6.699939503932244e-06,
      "loss": 0.3384,
      "step": 8590
    },
    {
      "epoch": 1.7342206089937489,
      "grad_norm": 0.4536168873310089,
      "learning_rate": 6.649526114135915e-06,
      "loss": 0.2009,
      "step": 8600
    },
    {
      "epoch": 1.736237144585602,
      "grad_norm": 9.48495864868164,
      "learning_rate": 6.599112724339585e-06,
      "loss": 0.2737,
      "step": 8610
    },
    {
      "epoch": 1.738253680177455,
      "grad_norm": 23.468605041503906,
      "learning_rate": 6.548699334543256e-06,
      "loss": 0.4613,
      "step": 8620
    },
    {
      "epoch": 1.7402702157693084,
      "grad_norm": 0.5489218831062317,
      "learning_rate": 6.498285944746925e-06,
      "loss": 0.4067,
      "step": 8630
    },
    {
      "epoch": 1.7422867513611615,
      "grad_norm": 5.216573715209961,
      "learning_rate": 6.447872554950596e-06,
      "loss": 0.3127,
      "step": 8640
    },
    {
      "epoch": 1.7443032869530146,
      "grad_norm": 27.357778549194336,
      "learning_rate": 6.397459165154265e-06,
      "loss": 0.4611,
      "step": 8650
    },
    {
      "epoch": 1.746319822544868,
      "grad_norm": 5.978736877441406,
      "learning_rate": 6.347045775357935e-06,
      "loss": 0.4648,
      "step": 8660
    },
    {
      "epoch": 1.748336358136721,
      "grad_norm": 11.77889633178711,
      "learning_rate": 6.296632385561606e-06,
      "loss": 0.3141,
      "step": 8670
    },
    {
      "epoch": 1.7503528937285742,
      "grad_norm": 2.062494993209839,
      "learning_rate": 6.246218995765276e-06,
      "loss": 0.2132,
      "step": 8680
    },
    {
      "epoch": 1.7523694293204275,
      "grad_norm": 13.569685935974121,
      "learning_rate": 6.1958056059689455e-06,
      "loss": 0.2535,
      "step": 8690
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 6.416600704193115,
      "learning_rate": 6.145392216172615e-06,
      "loss": 0.2489,
      "step": 8700
    },
    {
      "epoch": 1.756402500504134,
      "grad_norm": 12.254975318908691,
      "learning_rate": 6.094978826376286e-06,
      "loss": 0.1573,
      "step": 8710
    },
    {
      "epoch": 1.758419036095987,
      "grad_norm": 11.502562522888184,
      "learning_rate": 6.044565436579956e-06,
      "loss": 0.284,
      "step": 8720
    },
    {
      "epoch": 1.7604355716878404,
      "grad_norm": 32.055118560791016,
      "learning_rate": 5.994152046783626e-06,
      "loss": 0.3006,
      "step": 8730
    },
    {
      "epoch": 1.7624521072796935,
      "grad_norm": 77.8515396118164,
      "learning_rate": 5.943738656987296e-06,
      "loss": 0.2729,
      "step": 8740
    },
    {
      "epoch": 1.7644686428715466,
      "grad_norm": 0.9376232028007507,
      "learning_rate": 5.893325267190966e-06,
      "loss": 0.0904,
      "step": 8750
    },
    {
      "epoch": 1.7664851784634,
      "grad_norm": 22.321542739868164,
      "learning_rate": 5.842911877394636e-06,
      "loss": 0.2569,
      "step": 8760
    },
    {
      "epoch": 1.768501714055253,
      "grad_norm": 0.5024508833885193,
      "learning_rate": 5.792498487598307e-06,
      "loss": 0.2781,
      "step": 8770
    },
    {
      "epoch": 1.7705182496471061,
      "grad_norm": 0.12689660489559174,
      "learning_rate": 5.742085097801977e-06,
      "loss": 0.34,
      "step": 8780
    },
    {
      "epoch": 1.7725347852389595,
      "grad_norm": 1.117541790008545,
      "learning_rate": 5.691671708005647e-06,
      "loss": 0.3596,
      "step": 8790
    },
    {
      "epoch": 1.7745513208308128,
      "grad_norm": 0.21623137593269348,
      "learning_rate": 5.6412583182093165e-06,
      "loss": 0.3067,
      "step": 8800
    },
    {
      "epoch": 1.776567856422666,
      "grad_norm": 0.401699960231781,
      "learning_rate": 5.590844928412986e-06,
      "loss": 0.6839,
      "step": 8810
    },
    {
      "epoch": 1.778584392014519,
      "grad_norm": 10.671202659606934,
      "learning_rate": 5.540431538616657e-06,
      "loss": 0.3589,
      "step": 8820
    },
    {
      "epoch": 1.7806009276063723,
      "grad_norm": 9.159886360168457,
      "learning_rate": 5.490018148820327e-06,
      "loss": 0.3759,
      "step": 8830
    },
    {
      "epoch": 1.7826174631982254,
      "grad_norm": 44.1503791809082,
      "learning_rate": 5.439604759023998e-06,
      "loss": 0.2706,
      "step": 8840
    },
    {
      "epoch": 1.7846339987900786,
      "grad_norm": 28.549123764038086,
      "learning_rate": 5.389191369227667e-06,
      "loss": 0.2921,
      "step": 8850
    },
    {
      "epoch": 1.7866505343819319,
      "grad_norm": 0.608410656452179,
      "learning_rate": 5.3387779794313374e-06,
      "loss": 0.3061,
      "step": 8860
    },
    {
      "epoch": 1.788667069973785,
      "grad_norm": 42.62897872924805,
      "learning_rate": 5.288364589635007e-06,
      "loss": 0.3254,
      "step": 8870
    },
    {
      "epoch": 1.790683605565638,
      "grad_norm": 0.8175212144851685,
      "learning_rate": 5.237951199838677e-06,
      "loss": 0.0483,
      "step": 8880
    },
    {
      "epoch": 1.7927001411574914,
      "grad_norm": 0.5287079215049744,
      "learning_rate": 5.187537810042348e-06,
      "loss": 0.1531,
      "step": 8890
    },
    {
      "epoch": 1.7947166767493448,
      "grad_norm": 0.417889267206192,
      "learning_rate": 5.137124420246017e-06,
      "loss": 0.2228,
      "step": 8900
    },
    {
      "epoch": 1.7967332123411979,
      "grad_norm": 19.662059783935547,
      "learning_rate": 5.086711030449688e-06,
      "loss": 0.2948,
      "step": 8910
    },
    {
      "epoch": 1.798749747933051,
      "grad_norm": 0.10559473931789398,
      "learning_rate": 5.0362976406533575e-06,
      "loss": 0.3526,
      "step": 8920
    },
    {
      "epoch": 1.8007662835249043,
      "grad_norm": 53.312103271484375,
      "learning_rate": 4.985884250857028e-06,
      "loss": 0.3637,
      "step": 8930
    },
    {
      "epoch": 1.8027828191167574,
      "grad_norm": 0.950729489326477,
      "learning_rate": 4.935470861060698e-06,
      "loss": 0.2351,
      "step": 8940
    },
    {
      "epoch": 1.8047993547086105,
      "grad_norm": 88.6074447631836,
      "learning_rate": 4.885057471264369e-06,
      "loss": 0.3029,
      "step": 8950
    },
    {
      "epoch": 1.8068158903004639,
      "grad_norm": 2.446713447570801,
      "learning_rate": 4.834644081468038e-06,
      "loss": 0.2658,
      "step": 8960
    },
    {
      "epoch": 1.808832425892317,
      "grad_norm": 10.754137992858887,
      "learning_rate": 4.7842306916717085e-06,
      "loss": 0.2804,
      "step": 8970
    },
    {
      "epoch": 1.81084896148417,
      "grad_norm": 3.8297746181488037,
      "learning_rate": 4.733817301875378e-06,
      "loss": 0.6078,
      "step": 8980
    },
    {
      "epoch": 1.8128654970760234,
      "grad_norm": 0.343475341796875,
      "learning_rate": 4.683403912079048e-06,
      "loss": 0.311,
      "step": 8990
    },
    {
      "epoch": 1.8148820326678767,
      "grad_norm": 0.38984376192092896,
      "learning_rate": 4.632990522282719e-06,
      "loss": 0.361,
      "step": 9000
    },
    {
      "epoch": 1.8168985682597296,
      "grad_norm": 15.89024829864502,
      "learning_rate": 4.582577132486389e-06,
      "loss": 0.4152,
      "step": 9010
    },
    {
      "epoch": 1.818915103851583,
      "grad_norm": 4.52079963684082,
      "learning_rate": 4.532163742690059e-06,
      "loss": 0.227,
      "step": 9020
    },
    {
      "epoch": 1.8209316394434363,
      "grad_norm": 101.52201843261719,
      "learning_rate": 4.4817503528937285e-06,
      "loss": 0.3329,
      "step": 9030
    },
    {
      "epoch": 1.8229481750352894,
      "grad_norm": 0.24550792574882507,
      "learning_rate": 4.431336963097399e-06,
      "loss": 0.19,
      "step": 9040
    },
    {
      "epoch": 1.8249647106271425,
      "grad_norm": 46.069297790527344,
      "learning_rate": 4.380923573301069e-06,
      "loss": 0.5015,
      "step": 9050
    },
    {
      "epoch": 1.8269812462189958,
      "grad_norm": 4.579977512359619,
      "learning_rate": 4.330510183504739e-06,
      "loss": 0.3198,
      "step": 9060
    },
    {
      "epoch": 1.828997781810849,
      "grad_norm": 0.25756141543388367,
      "learning_rate": 4.280096793708409e-06,
      "loss": 0.2372,
      "step": 9070
    },
    {
      "epoch": 1.831014317402702,
      "grad_norm": 46.36560821533203,
      "learning_rate": 4.229683403912079e-06,
      "loss": 0.4119,
      "step": 9080
    },
    {
      "epoch": 1.8330308529945554,
      "grad_norm": 12.164412498474121,
      "learning_rate": 4.179270014115749e-06,
      "loss": 0.3088,
      "step": 9090
    },
    {
      "epoch": 1.8350473885864087,
      "grad_norm": 10.883941650390625,
      "learning_rate": 4.128856624319419e-06,
      "loss": 0.3492,
      "step": 9100
    },
    {
      "epoch": 1.8370639241782616,
      "grad_norm": 50.459625244140625,
      "learning_rate": 4.07844323452309e-06,
      "loss": 0.4156,
      "step": 9110
    },
    {
      "epoch": 1.839080459770115,
      "grad_norm": 2.445526361465454,
      "learning_rate": 4.02802984472676e-06,
      "loss": 0.2547,
      "step": 9120
    },
    {
      "epoch": 1.8410969953619682,
      "grad_norm": 9.128018379211426,
      "learning_rate": 3.97761645493043e-06,
      "loss": 0.2565,
      "step": 9130
    },
    {
      "epoch": 1.8431135309538214,
      "grad_norm": 12.074620246887207,
      "learning_rate": 3.9272030651340996e-06,
      "loss": 0.5465,
      "step": 9140
    },
    {
      "epoch": 1.8451300665456745,
      "grad_norm": 27.472700119018555,
      "learning_rate": 3.8767896753377694e-06,
      "loss": 0.2066,
      "step": 9150
    },
    {
      "epoch": 1.8471466021375278,
      "grad_norm": 7.436228275299072,
      "learning_rate": 3.82637628554144e-06,
      "loss": 0.3236,
      "step": 9160
    },
    {
      "epoch": 1.849163137729381,
      "grad_norm": 5.266705513000488,
      "learning_rate": 3.7759628957451104e-06,
      "loss": 0.1982,
      "step": 9170
    },
    {
      "epoch": 1.851179673321234,
      "grad_norm": 9.23135757446289,
      "learning_rate": 3.7255495059487803e-06,
      "loss": 0.3279,
      "step": 9180
    },
    {
      "epoch": 1.8531962089130873,
      "grad_norm": 24.27978515625,
      "learning_rate": 3.67513611615245e-06,
      "loss": 0.2215,
      "step": 9190
    },
    {
      "epoch": 1.8552127445049407,
      "grad_norm": 25.402143478393555,
      "learning_rate": 3.62472272635612e-06,
      "loss": 0.3353,
      "step": 9200
    },
    {
      "epoch": 1.8572292800967936,
      "grad_norm": 14.624580383300781,
      "learning_rate": 3.5743093365597903e-06,
      "loss": 0.3703,
      "step": 9210
    },
    {
      "epoch": 1.8592458156886469,
      "grad_norm": 2.0033836364746094,
      "learning_rate": 3.5238959467634606e-06,
      "loss": 0.1799,
      "step": 9220
    },
    {
      "epoch": 1.8612623512805002,
      "grad_norm": 9.069219589233398,
      "learning_rate": 3.473482556967131e-06,
      "loss": 0.3747,
      "step": 9230
    },
    {
      "epoch": 1.8632788868723533,
      "grad_norm": 41.32433319091797,
      "learning_rate": 3.4230691671708003e-06,
      "loss": 0.3085,
      "step": 9240
    },
    {
      "epoch": 1.8652954224642064,
      "grad_norm": 9.95955753326416,
      "learning_rate": 3.3726557773744706e-06,
      "loss": 0.4332,
      "step": 9250
    },
    {
      "epoch": 1.8673119580560598,
      "grad_norm": 16.716472625732422,
      "learning_rate": 3.322242387578141e-06,
      "loss": 0.4,
      "step": 9260
    },
    {
      "epoch": 1.8693284936479129,
      "grad_norm": 8.608214378356934,
      "learning_rate": 3.271828997781811e-06,
      "loss": 0.2501,
      "step": 9270
    },
    {
      "epoch": 1.871345029239766,
      "grad_norm": 18.54879379272461,
      "learning_rate": 3.221415607985481e-06,
      "loss": 0.4985,
      "step": 9280
    },
    {
      "epoch": 1.8733615648316193,
      "grad_norm": 18.894426345825195,
      "learning_rate": 3.1710022181891514e-06,
      "loss": 0.2606,
      "step": 9290
    },
    {
      "epoch": 1.8753781004234726,
      "grad_norm": 0.8378769159317017,
      "learning_rate": 3.1205888283928212e-06,
      "loss": 0.5818,
      "step": 9300
    },
    {
      "epoch": 1.8773946360153255,
      "grad_norm": 3.5139544010162354,
      "learning_rate": 3.070175438596491e-06,
      "loss": 0.4026,
      "step": 9310
    },
    {
      "epoch": 1.8794111716071789,
      "grad_norm": 0.9300795197486877,
      "learning_rate": 3.0197620488001614e-06,
      "loss": 0.2758,
      "step": 9320
    },
    {
      "epoch": 1.8814277071990322,
      "grad_norm": 11.028329849243164,
      "learning_rate": 2.9693486590038317e-06,
      "loss": 0.2553,
      "step": 9330
    },
    {
      "epoch": 1.8834442427908853,
      "grad_norm": 2.3765084743499756,
      "learning_rate": 2.9189352692075015e-06,
      "loss": 0.2713,
      "step": 9340
    },
    {
      "epoch": 1.8854607783827384,
      "grad_norm": 4.728377819061279,
      "learning_rate": 2.868521879411172e-06,
      "loss": 0.2363,
      "step": 9350
    },
    {
      "epoch": 1.8874773139745917,
      "grad_norm": 0.5992971062660217,
      "learning_rate": 2.818108489614842e-06,
      "loss": 0.2848,
      "step": 9360
    },
    {
      "epoch": 1.8894938495664448,
      "grad_norm": 16.628684997558594,
      "learning_rate": 2.767695099818512e-06,
      "loss": 0.3002,
      "step": 9370
    },
    {
      "epoch": 1.891510385158298,
      "grad_norm": 1.2225267887115479,
      "learning_rate": 2.717281710022182e-06,
      "loss": 0.2921,
      "step": 9380
    },
    {
      "epoch": 1.8935269207501513,
      "grad_norm": 0.8294436931610107,
      "learning_rate": 2.666868320225852e-06,
      "loss": 0.378,
      "step": 9390
    },
    {
      "epoch": 1.8955434563420044,
      "grad_norm": 1.4724771976470947,
      "learning_rate": 2.616454930429522e-06,
      "loss": 0.1976,
      "step": 9400
    },
    {
      "epoch": 1.8975599919338575,
      "grad_norm": 0.36533427238464355,
      "learning_rate": 2.5660415406331923e-06,
      "loss": 0.3103,
      "step": 9410
    },
    {
      "epoch": 1.8995765275257108,
      "grad_norm": 7.922908306121826,
      "learning_rate": 2.5156281508368626e-06,
      "loss": 0.3305,
      "step": 9420
    },
    {
      "epoch": 1.9015930631175642,
      "grad_norm": 12.604528427124023,
      "learning_rate": 2.4652147610405324e-06,
      "loss": 0.3856,
      "step": 9430
    },
    {
      "epoch": 1.9036095987094173,
      "grad_norm": 3.1227188110351562,
      "learning_rate": 2.4148013712442027e-06,
      "loss": 0.4009,
      "step": 9440
    },
    {
      "epoch": 1.9056261343012704,
      "grad_norm": 38.824241638183594,
      "learning_rate": 2.364387981447873e-06,
      "loss": 0.4034,
      "step": 9450
    },
    {
      "epoch": 1.9076426698931237,
      "grad_norm": 21.207717895507812,
      "learning_rate": 2.313974591651543e-06,
      "loss": 0.2551,
      "step": 9460
    },
    {
      "epoch": 1.9096592054849768,
      "grad_norm": 4.471958160400391,
      "learning_rate": 2.2635612018552127e-06,
      "loss": 0.3499,
      "step": 9470
    },
    {
      "epoch": 1.91167574107683,
      "grad_norm": 44.77265167236328,
      "learning_rate": 2.2131478120588826e-06,
      "loss": 0.401,
      "step": 9480
    },
    {
      "epoch": 1.9136922766686832,
      "grad_norm": 2.4889590740203857,
      "learning_rate": 2.162734422262553e-06,
      "loss": 0.415,
      "step": 9490
    },
    {
      "epoch": 1.9157088122605364,
      "grad_norm": 0.4893801808357239,
      "learning_rate": 2.112321032466223e-06,
      "loss": 0.1428,
      "step": 9500
    },
    {
      "epoch": 1.9177253478523895,
      "grad_norm": 0.4854009449481964,
      "learning_rate": 2.061907642669893e-06,
      "loss": 0.3658,
      "step": 9510
    },
    {
      "epoch": 1.9197418834442428,
      "grad_norm": 0.6545568704605103,
      "learning_rate": 2.0114942528735633e-06,
      "loss": 0.4085,
      "step": 9520
    },
    {
      "epoch": 1.9217584190360961,
      "grad_norm": 8.526740074157715,
      "learning_rate": 1.9610808630772336e-06,
      "loss": 0.2268,
      "step": 9530
    },
    {
      "epoch": 1.9237749546279492,
      "grad_norm": 9.5822172164917,
      "learning_rate": 1.9106674732809035e-06,
      "loss": 0.3076,
      "step": 9540
    },
    {
      "epoch": 1.9257914902198023,
      "grad_norm": 0.5030128955841064,
      "learning_rate": 1.8602540834845736e-06,
      "loss": 0.3453,
      "step": 9550
    },
    {
      "epoch": 1.9278080258116557,
      "grad_norm": 2.8761634826660156,
      "learning_rate": 1.8098406936882438e-06,
      "loss": 0.272,
      "step": 9560
    },
    {
      "epoch": 1.9298245614035088,
      "grad_norm": 5.978741645812988,
      "learning_rate": 1.7594273038919137e-06,
      "loss": 0.4777,
      "step": 9570
    },
    {
      "epoch": 1.9318410969953619,
      "grad_norm": 18.043107986450195,
      "learning_rate": 1.7090139140955838e-06,
      "loss": 0.2941,
      "step": 9580
    },
    {
      "epoch": 1.9338576325872152,
      "grad_norm": 10.644655227661133,
      "learning_rate": 1.658600524299254e-06,
      "loss": 0.2926,
      "step": 9590
    },
    {
      "epoch": 1.9358741681790683,
      "grad_norm": 3.056931495666504,
      "learning_rate": 1.608187134502924e-06,
      "loss": 0.3952,
      "step": 9600
    },
    {
      "epoch": 1.9378907037709214,
      "grad_norm": 0.8825253248214722,
      "learning_rate": 1.5577737447065942e-06,
      "loss": 0.2714,
      "step": 9610
    },
    {
      "epoch": 1.9399072393627748,
      "grad_norm": 10.56422233581543,
      "learning_rate": 1.5073603549102643e-06,
      "loss": 0.4321,
      "step": 9620
    },
    {
      "epoch": 1.941923774954628,
      "grad_norm": 16.04387855529785,
      "learning_rate": 1.4569469651139342e-06,
      "loss": 0.2858,
      "step": 9630
    },
    {
      "epoch": 1.9439403105464812,
      "grad_norm": 8.117372512817383,
      "learning_rate": 1.4065335753176045e-06,
      "loss": 0.3341,
      "step": 9640
    },
    {
      "epoch": 1.9459568461383343,
      "grad_norm": 0.681434690952301,
      "learning_rate": 1.3561201855212745e-06,
      "loss": 0.1255,
      "step": 9650
    },
    {
      "epoch": 1.9479733817301876,
      "grad_norm": 38.436134338378906,
      "learning_rate": 1.3057067957249446e-06,
      "loss": 0.3704,
      "step": 9660
    },
    {
      "epoch": 1.9499899173220407,
      "grad_norm": 8.613871574401855,
      "learning_rate": 1.2552934059286147e-06,
      "loss": 0.3153,
      "step": 9670
    },
    {
      "epoch": 1.9520064529138939,
      "grad_norm": 9.426512718200684,
      "learning_rate": 1.2048800161322848e-06,
      "loss": 0.1074,
      "step": 9680
    },
    {
      "epoch": 1.9540229885057472,
      "grad_norm": 0.6328140497207642,
      "learning_rate": 1.1544666263359548e-06,
      "loss": 0.288,
      "step": 9690
    },
    {
      "epoch": 1.9560395240976003,
      "grad_norm": 0.3578307032585144,
      "learning_rate": 1.104053236539625e-06,
      "loss": 0.2808,
      "step": 9700
    },
    {
      "epoch": 1.9580560596894534,
      "grad_norm": 9.91516399383545,
      "learning_rate": 1.0536398467432952e-06,
      "loss": 0.3796,
      "step": 9710
    },
    {
      "epoch": 1.9600725952813067,
      "grad_norm": 2.2492523193359375,
      "learning_rate": 1.003226456946965e-06,
      "loss": 0.1821,
      "step": 9720
    },
    {
      "epoch": 1.96208913087316,
      "grad_norm": 3.453979253768921,
      "learning_rate": 9.528130671506351e-07,
      "loss": 0.3702,
      "step": 9730
    },
    {
      "epoch": 1.964105666465013,
      "grad_norm": 19.438684463500977,
      "learning_rate": 9.023996773543054e-07,
      "loss": 0.5894,
      "step": 9740
    },
    {
      "epoch": 1.9661222020568663,
      "grad_norm": 0.627170741558075,
      "learning_rate": 8.519862875579754e-07,
      "loss": 0.2664,
      "step": 9750
    },
    {
      "epoch": 1.9681387376487196,
      "grad_norm": 5.590874671936035,
      "learning_rate": 8.015728977616455e-07,
      "loss": 0.3714,
      "step": 9760
    },
    {
      "epoch": 1.9701552732405727,
      "grad_norm": 11.288686752319336,
      "learning_rate": 7.511595079653157e-07,
      "loss": 0.3573,
      "step": 9770
    },
    {
      "epoch": 1.9721718088324258,
      "grad_norm": 29.10493278503418,
      "learning_rate": 7.007461181689857e-07,
      "loss": 0.3925,
      "step": 9780
    },
    {
      "epoch": 1.9741883444242792,
      "grad_norm": 2.3565828800201416,
      "learning_rate": 6.503327283726558e-07,
      "loss": 0.2372,
      "step": 9790
    },
    {
      "epoch": 1.9762048800161323,
      "grad_norm": 0.2914453148841858,
      "learning_rate": 5.999193385763259e-07,
      "loss": 0.2064,
      "step": 9800
    },
    {
      "epoch": 1.9782214156079854,
      "grad_norm": 2.6038999557495117,
      "learning_rate": 5.49505948779996e-07,
      "loss": 0.2199,
      "step": 9810
    },
    {
      "epoch": 1.9802379511998387,
      "grad_norm": 0.5708178877830505,
      "learning_rate": 4.99092558983666e-07,
      "loss": 0.2933,
      "step": 9820
    },
    {
      "epoch": 1.982254486791692,
      "grad_norm": 1.1807599067687988,
      "learning_rate": 4.4867916918733623e-07,
      "loss": 0.312,
      "step": 9830
    },
    {
      "epoch": 1.984271022383545,
      "grad_norm": 5.400322914123535,
      "learning_rate": 3.9826577939100626e-07,
      "loss": 0.3144,
      "step": 9840
    },
    {
      "epoch": 1.9862875579753982,
      "grad_norm": 2.9682161808013916,
      "learning_rate": 3.4785238959467633e-07,
      "loss": 0.2029,
      "step": 9850
    },
    {
      "epoch": 1.9883040935672516,
      "grad_norm": 10.514266014099121,
      "learning_rate": 2.9743899979834646e-07,
      "loss": 0.2358,
      "step": 9860
    },
    {
      "epoch": 1.9903206291591047,
      "grad_norm": 0.9472855925559998,
      "learning_rate": 2.4702561000201654e-07,
      "loss": 0.1693,
      "step": 9870
    },
    {
      "epoch": 1.9923371647509578,
      "grad_norm": 15.112974166870117,
      "learning_rate": 1.9661222020568664e-07,
      "loss": 0.4153,
      "step": 9880
    },
    {
      "epoch": 1.9943537003428111,
      "grad_norm": 18.866283416748047,
      "learning_rate": 1.4619883040935672e-07,
      "loss": 0.4148,
      "step": 9890
    },
    {
      "epoch": 1.9963702359346642,
      "grad_norm": 19.229063034057617,
      "learning_rate": 9.578544061302682e-08,
      "loss": 0.3601,
      "step": 9900
    },
    {
      "epoch": 1.9983867715265173,
      "grad_norm": 2.717512845993042,
      "learning_rate": 4.537205081669691e-08,
      "loss": 0.2601,
      "step": 9910
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.3641037344932556,
      "eval_runtime": 592.2626,
      "eval_samples_per_second": 16.744,
      "eval_steps_per_second": 2.094,
      "step": 9918
    }
  ],
  "logging_steps": 10,
  "max_steps": 9918,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5218150005427200.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
